{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/visnja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/visnja/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "import contractions\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics\n",
    "\n",
    "# to avoid future warnings for sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "connection=MongoClient(\"mongodb://localhost:27017/crawler.contents\")\n",
    "\n",
    "db=connection.get_database()\n",
    "articles = pd.DataFrame(list(db.contents.find()))\n",
    "articles = articles.drop(columns=['visited','alternateImageUrl','created_at','contentType','date','icon','publishedAt','source','url'])\n",
    "articles = articles.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(articles.classes_target.dropna().values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([articles,articles['classes_target'].fillna(\"\").map(lambda x: \",\".join(x)).str.get_dummies(sep=\",\")],axis=1)\n",
    "counts = []\n",
    "for i in classes:\n",
    "    counts.append((i,df[i].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(counts, columns=['cat','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EUR</td>\n",
       "      <td>12751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZD</td>\n",
       "      <td>2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBP</td>\n",
       "      <td>7172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TWD</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MXN</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAD</td>\n",
       "      <td>2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RUB</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XAU</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USD</td>\n",
       "      <td>19259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHF</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JPY</td>\n",
       "      <td>6399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ARS</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNY</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OIL</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TRY</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AUD</td>\n",
       "      <td>4946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INDEX</td>\n",
       "      <td>10092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BTC</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  count\n",
       "0     EUR  12751\n",
       "1     NZD   2953\n",
       "2     GBP   7172\n",
       "3     TWD     72\n",
       "4     MXN    582\n",
       "5     CAD   2620\n",
       "6     RUB    352\n",
       "7     XAU   1446\n",
       "8     USD  19259\n",
       "9     CHF   1600\n",
       "10    JPY   6399\n",
       "11    ARS     17\n",
       "12    CNY   1522\n",
       "13    OIL   1988\n",
       "14    TRY   1069\n",
       "15    AUD   4946\n",
       "16  INDEX  10092\n",
       "17    BTC   1096"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'category')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFlCAYAAACUQvD0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8IElEQVR4nO3deZhcRb3/8fcHohgISwI4QhIImygQRBMRRSARlFyBC/gDCRdZFEW5qCAo2/UqilxwQRRBFAHDogQussmiF8GAaAATthAWCRBIAMMOCauB7++PqoaTnp6ZnunT3TOTz+t5+pnTdc6pqnN6uvvbdarqKCIwMzOzpdsy7a6AmZmZtZ8DAjMzM3NAYGZmZg4IzMzMDAcEZmZmhgMCMzMzwwGBWctImiLpe20qW5J+LelZSbc0qYy1JC2StGwP202QNL8ZdTCzvnNAYEstSXMlLZC0QiHt85KmtbFazfJR4OPAqIjYvIwM8/nbrvI8Ih6JiGER8XoZ+Q8GkvaTdGO762FWDwcEtrQbAhzc7kr0Vk+/wmtYG5gbES+WUPaQRvPozwbL8Q2W47DWcUBgS7sfAl+XtEr1CkljJEXxg1XSNEmfz8v7SfqrpJMkPSfpQUkfyenzJD0had+qbFeTdI2khZKul7R2Ie/35HXPSLpP0qcL66ZIOk3SVZJeBCbWqO+aki7P+8+R9IWcvj9wBvDh3KT/nRr7rifpOklPS3pK0m+K5yS3Bhwh6U7gRUnnA2sBv895Hl59viSNyJcpHsuXKi6t9QLkev9O0pOSHpL01cK6zSXNkPRCbs35cRd5TJA0X9LRuf5zJe1VWL+cpB9JeiTn8wtJQ6v2PULSP4Ffd1HGFyTdk1+7uyV9IKcfKemBQvquOf29wC8K5/25nuqS1x8u6fF83j6fz+n6ed3Kks7J5+phSd+UtExeV/x/fAY4Nv8vjC3k/U5JL0tavdYx2lIuIvzwY6l8AHOB7YCLge/ltM8D0/LyGCCAIYV9pgGfz8v7AYuBzwLLAt8DHgFOBZYDPgEsBIbl7afk51vn9T8FbszrVgDm5byGAB8AngI2Luz7PLAlKZB/R43juR74OfAOYDPgSWDbQl1v7OZcrE+6pLAcsDpwA/CTqnN1OzAaGFo8f4VtljhfwJXABcBw4G3ANjl9AjA/Ly8DzAS+BbwdWBd4ENg+r58O7J2XhwFbdFH/Cfm1+HE+hm2AF4EN8/qfAJcDI4AVgd8Dx1ft+/2879Aa+e8OPAp8EFA+X2sX1q2Zj2WPXO4aXZ33HuoyCfgnsDGwPHBuPqfr5/XnAJfl/cYA/wD2r/p//Arpf2go6f/h+4WyDwZ+3+73nh/989H2CvjhR7sevBUQbEL6sl2d3gcE9xfWjc3bdxTSngY2y8tTgKmFdcOA10lfsnsAf6mq3y+Bbxf2PaebYxmd81qxkHY8MKVQ1y4Dghr57QLcVnWuPlfr/BWev3m+gDWAN4DhNfKewFsBwYeAR6rWHwX8Oi/fAHwHWK2H+k7IX4YrFNIuBP6b9AX+IrBeYd2HgYcK+75GjSCrsP0fgYPrPHe3AzvXOu911OUscnCQn6+fz+n6pKDzVWCjwvov8tb/6341zuWHSIHmMvn5DODT7Xi/+dH/H77GZEu9iLhL0hXAkcA9vdx9QWH55ZxfddqwwvN5hXIX5abdNUnX+D9UaVbOhpB+IXbat4Y1gWciYmEh7WFgfB3HgKR3AicDW5F+fS4DPFu1WXflVxud61OdR7W1gTWrjntZ4C95eX/gu8C9kh4CvhMRV3SR17OxZB+Jh0nnZXXSr+2ZkirrlMupeDIiXunheB6otULSPsChpIAI0uu9Whf59FSXNUlf2hXFc74aqRXl4ULaw8DILrYnIm7Ol5i2kfQ4KbC4vIu62VLOAYFZ8m3gVuDEQlrly2V54IW8/K4GyxldWZA0jNRs/Bjpg/z6iPh4N/t2d2vSx4ARklYsBAVrkZq563F8zn/TiHha0i7AKT2U31195uX6rBIRz/Ww3UMRsUGtlRFxP7Bnvk7+KeAiSatG7c6RwyWtUFi3FnAX6dLLy6TLL12dj55u+zoPWK86MfcB+RWwLTA9Il6XdDvpS75Wvj3V5XFgVOH56MLyU8C/SEHU3Tmt+jWudRxnA58hXYq4qIfAx5Zi7lRoBkTEHNL17q8W0p4kfdh+RtKykj5HjS+FXvqkpI9KejtwLHBzRMwDrgDeLWlvSW/Ljw/mjmn11H8e8DfgeEnvkLQp6df1b+qs14rAIuA5SSOBb9SxzwLSNf9a9XkcuBr4uaTh+Xi2rrHpLcALuUPf0HyeN5H0QQBJn5G0ekS8ATyX9+luWON3JL1d0lbAjsD/5n1/BZyUW0KQNFLS9nUcY8UZpM6n45Ssn4OBFUhfwk/mfD9LugRVsQAYlV9v6qjLhcBnJb1X0vKkvhXkfV/P64+TtGIu/1DgvB7qfi6wKykoOKcXx2xLGQcEZm/5LukDvugLpC/Hp0kdvf7WYBm/JbVGPAOMA/YCyL/qPwFMJv3a/ydvdXKr156kZuvHgEtI/Q+uqXPf75A6Mj5P6gx4cR37HA98U2mExddrrN+b9Iv2XuAJ4JDqDfKX3E6kTpAPkX4FnwGsnDeZBMyWtIjUCXNyN79w/0m6zPEYKRD6UkTcm9cdAcwBbpL0AvAnYMM6jrFSz/8FjiO9fguBS4EREXE3qVVpOunLfyzw18Ku1wGzgX9KeqqnukTE1aRLN3/O20zP+7ya/36F1HL1IHBjrs9ZPdR9Pqn1K3jrUoxZJ4roqaXMzKx/kzQBOC8iRvWw6YCSW4juApaLiMUN5HMW8FhEfLO0ytmg4xYCM7N+RNKu+bLHcFIr0e8bDAbGkPpfnFlSFW2QckBgZta/fJHUJ+EBUn+JA/uakaRjSS0MP4yIh8qpng1WvmRgZmZmbiEwMzOzFgUEkkZL+nOeB3y2pINz+giludvvz3+HF/Y5Smk+9vuKw4PysJ9Zed3JyrN7KM0PfkFOvzlfNzMzM7M6tOSSgaQ1SHN73yppRdLc5buQptp8JiJOkHQkaZrTIyRtBJwPbE6auetPwLvzpB+3kObjvgm4Cjg5Iq6W9J+kSVW+JGkysGtE7NFdvVZbbbUYM2ZM3cfx4osvssIK1aPSyuUy+k8Zg+EYXEb/yd9l9K8yBsMx9KWMmTNnPhURtW9u1Y75kkk35/g4cB9v3QRkDeC+vHwUcFRh+z+S5vteA7i3kL4n8MviNnl5CGk8s7qrx7hx46I3/vznP/dq+75wGf2njMFwDC6j/+TvMvpXGYPhGPpSBjAjuvhObHkfgtyU/37gZtJNYB6HN2c2e2febCRLzsk9P6eNzMvV6UvsE2mIzvPAqk05CDMzs0GmpaMM8tzt1wPHRcTFkp6LiFUK65+NiOGSTiXNC35eTj+TdHngEdKdwLbL6VsBh0fETpJmk26ZOj+vewDYPCKerqrDAcABAB0dHeOmTp1ad/0XLVrEsGHDet6wAS6j/5QxGI7BZfSf/F1G/ypjMBxDX8qYOHHizIiofdOzrpoOyn6Q7of+R+DQQpovGbiMflvGYDgGl9F/8ncZ/auMwXAMfSmDdl8yyCMBzgTuiYgfF1ZdDuybl/cl9S2opE/OIwfWATYAbol0WWGhpC1ynvtU7VPJazfgunzwZmZm1oNW3f54S9KNTmblW4MCHA2cAFwoaX/S5YDdASJitqQLSbf4XAwcFOkmKJBm7ZoCDCXdTe3qnH4mcK6kOaQbx0xu8jGZmZkNGi0JCCLiRt66P3i1bbvY5zjS3cWq02ew5O1FK+mvkAMKMzMz6x3PVGhmZmYOCMzMzMwBgZmZmeGAwMzMzHBAYGZmZrRu2KGZDQJjjryyZvphYxezX411c0/YodlVMrOSuIXAzMzMHBCYmZmZAwIzMzPDAYGZmZnhgMDMzMxwQGBmZmY4IDAzMzMcEJiZmRkOCMzMzAwHBGZmZoYDAjMzM8MBgZmZmeGAwMzMzHBAYGZmZjggMDMzMxwQmJmZGQ4IzMzMDAcEZmZmhgMCMzMzo0UBgaSzJD0h6a5C2gWSbs+PuZJuz+ljJL1cWPeLwj7jJM2SNEfSyZKU05fL+c2RdLOkMa04LjMzs8GiVS0EU4BJxYSI2CMiNouIzYDfARcXVj9QWRcRXyqknwYcAGyQH5U89weejYj1gZOA7zflKMzMzAaplgQEEXED8EytdflX/qeB87vLQ9IawEoRMT0iAjgH2CWv3hk4Oy9fBGxbaT0wMzOznil9t7agoNSMf0VEbFKVvjXw44gYX9huNvAP4AXgmxHxF0njgRMiYru83VbAERGxY74UMSki5ud1DwAfioinatTjAFIrAx0dHeOmTp1a9zEsWrSIYcOG9e7Ae8ll9J8yBsMxlF3GrEefr5neMRQWvNw5fezIlUspF/x6u4yBlX9/LWPixIkzK9+31YaUVqu+25MlWwceB9aKiKcljQMulbQxUOsXfyWa6W7dkokRpwOnA4wfPz4mTJhQd0WnTZtGb7bvC5fRf8oYDMdQdhn7HXllzfTDxi7mxFmdP07m7lVOueDX22UMrPwHYhltDQgkDQE+BYyrpEXEq8CreXlm/rX/bmA+MKqw+yjgsbw8HxgNzM95rkwXlyjMzMyss3YPO9wOuLfS1A8gaXVJy+bldUmdBx+MiMeBhZK2yP0D9gEuy7tdDuybl3cDrotWXQsxMzMbBFo17PB8YDqwoaT5kvbPqybTuTPh1sCdku4gdRD8UkRUfu0fCJwBzAEeAK7O6WcCq0qaAxwKHNm0gzEzMxuEWnLJICL27CJ9vxppvyMNQ6y1/QxgkxrprwC7N1ZLMzOzpVe7LxmYmZlZP+CAwMzMzBwQmJmZmQMCMzMzwwGBmZmZ4YDAzMzMcEBgZmZmOCAwMzMzHBCYmZkZDgjMzMwMBwRmZmaGAwIzMzPDAYGZmZnhgMDMzMxwQGBmZmY4IDAzMzMcEJiZmRkOCMzMzAwHBGZmZoYDAjMzM8MBgZmZmeGAwMzMzHBAYGZmZjggMDMzM1oUEEg6S9ITku4qpB0j6VFJt+fHJwvrjpI0R9J9krYvpI+TNCuvO1mScvpyki7I6TdLGtOK4zIzMxssWtVCMAWYVCP9pIjYLD+uApC0ETAZ2Djv83NJy+btTwMOADbIj0qe+wPPRsT6wEnA95t1IGZmZoNRSwKCiLgBeKbOzXcGpkbEqxHxEDAH2FzSGsBKETE9IgI4B9ilsM/ZefkiYNtK64GZmZn1rN19CL4s6c58SWF4ThsJzCtsMz+njczL1elL7BMRi4HngVWbWXEzM7PBROnHdgsKStf1r4iITfLzDuApIIBjgTUi4nOSTgWmR8R5ebszgauAR4DjI2K7nL4VcHhE7CRpNrB9RMzP6x4ANo+Ip2vU4wDSZQc6OjrGTZ06te5jWLRoEcOGDevT8buMgVfGYDiGssuY9ejzNdM7hsKClzunjx25cinlgl9vlzGw8u+vZUycOHFmRIyvtW5IabXqpYhYUFmW9Cvgivx0PjC6sOko4LGcPqpGenGf+ZKGACvTxSWKiDgdOB1g/PjxMWHChLrrPG3aNHqzfV+4jP5TxmA4hrLL2O/IK2umHzZ2MSfO6vxxMnevcsoFv94uY2DlPxDLaNslg9wnoGJXoDIC4XJgch45sA6p8+AtEfE4sFDSFrl/wD7AZYV99s3LuwHXRauaPszMzAaBlrQQSDofmACsJmk+8G1ggqTNSJcM5gJfBIiI2ZIuBO4GFgMHRcTrOasDSSMWhgJX5wfAmcC5kuaQWgYmN/2gzMzMBpGWBAQRsWeN5DO72f444Lga6TOATWqkvwLs3kgdzczMlmbtHmVgZmZm/YADAjMzM3NAYGZmZg4IzMzMDAcEZmZmhgMCMzMzwwGBmZmZ4YDAzMzMcEBgZmZmOCAwMzMz+hgQSJooaeuyK2NmZmbtUVdAIOl6SVvm5SOAqcD5ko5uZuXMzMysNeptIdgEuCkvf4F058ItgC81oU5mZmbWYvXe7XAZICStBygi7gGQNLxpNTMzM7OWqTcguBE4BVgDuAQgBwdPNaleZmZm1kL1XjLYD3gOuBM4Jqe9B/hp6TUyMzOzlqurhSAingaOrkq7sik1MjMzs5ard5TBcpKOk/SgpOdz2ickfbm51TMzM7NWqPeSwUmkkQZ7AZHTZgMHNqNSZmZm1lr1dircFVg/Il6U9AZARDwqaWTzqmZmZmatUm8LwWtUBQ+SVgeeLr1GZmZm1nL1BgT/C5wtaR0ASWuQhiFObVbFzMzMrHXqDQiOBuYCs4BVgPuBx4DvNqVWZmZm1lL1Djt8DTgEOCRfKngqIqL7vczMzGygqHfY4T6SNgWIiCcjIiS9T9Leza2emZmZtUK9owyOBTarSpsHXA6c29POks4CdgSeiIhNctoPgZ1IHRYfAD4bEc9JGgPcA9yXd78pIr6U9xkHTAGGAlcBB+fgZDngHGAcqaPjHhExt85j62TMkbXnXDps7GL262Ld3BN26GtxZmZmbVdvH4KVgBeq0p4n9SeoxxRgUlXaNcAmEbEp8A/gqMK6ByJis/wo3lHxNOAAYIP8qOS5P/BsRKxPmjPh+3XWy8zMzKg/ILgb+H9VabuSfsn3KCJuAJ6pSvu/iFicn94EjOoujzyyYaWImJ77L5wD7JJX7wycnZcvAraVpHrqZmZmZvVfMjgCuErSHqTm/fWBbYFPllSPzwEXFJ6vI+k2UqvENyPiL8BIYH5hm/k5jfx3HkBELM7TK6+K78ZoZmZWF9U7WEDSWsB/AKNJX76/iYh5dReU+gZcUelDUEj/L2A88KlCf4BhEfF07jNwKbAxsCFwfERsl/fbCjg8InaSNBvYPiLm53UPAJvnmzJV1+MA0mUHOjo6xk2d2nkqhVmPPl/zGDqGwoKXax/f2JEr93QK6rJo0SKGDRtWSl4uo3/nPxDL6O17o6z3Bfj1dhkDK//+WsbEiRNnRsT4WuvqbSEgIh4BTqi71DpI2pfU2XDbyjDGiHgVeDUvz8xf7u8mtQgULyuMIs2FQF43GpgvaQiwMlWXKArHcTpwOsD48eNjwoQJnbbpquPgYWMXc+Ks2qds7l6d8+mLadOmUatOZXIZ/SP/gVhGb98bZb0vwK+3yxhY+Q/EMuoKCCSNAL5OGmmwRCgSEVv3pWBJk0iXIraJiJcK6asDz0TE65LWJXUefDAinpG0UNIWwM3APsDP8m6XA/sC04HdgOs8T4KZmVn96m0h+C2wHHAh8FIP23Yi6XxgArCapPnAt0mjCpYDrsn9/yrDC7cGvitpMfA68KWIqPzaP5C3hh1enR8AZwLnSppDahmY3Ns6mpmZLc3qDQg+Aqyem/N7LSL2rJF8Zhfb/g74XRfrZpBuw1yd/gqwe1/qZmZmZvUPO7yTHoYFmpmZ2cBVbwvBdcAfJP0a+GdxRUScVXqtzMzMrKXqDQi2IvXk/3hVegAOCMzMzAa4eu92OLHZFTEzM7P2qbcPAZJWlbS3pG/k52tKcr8CMzOzQaDe2x9vQ7r74F7At3LyBqSbDZmZmdkAV28LwU9ItxSeBFRuSHQzsHkzKmVmZmatVW9AMCYirs3LlRkAX6MXUx+bmZlZ/1X37Y8lbV+Vth0wq+T6mJmZWRvU+wv/MOAKSVcCQyX9EtgJ2LlpNTMzM7OWqbeF4BZgU2A2ad6Bh0i3F/57sypmZmZmrdNjC4GkZYFFwCoR8YPmV8nMzMxarccWgoh4HfgHsGrzq2NmZmbtUG8fgt+Q+hD8lDSFcWWkARFxXTMqZmZmZq1Tb0BwYP57TFV6AOuWVhszMzNri3r6ECwDfB64MSJebX6VzMzMrNXq6UPwBnCpgwEzM7PBq95hhzdI2qKpNTEzM7O2qbcPwcPA1ZIuA+axZKfCb3W5l5mZmQ0I9QYEQ4FL87JveWxmZjbI1BUQRMRnm10RMzMza5+6AgJJXQ4tjIgHy6uOmZmZtUO9lwzmkPoNqJBW6UewbKk1MjMzs5ar95LBEqMRJL0L+Dbwl2ZUyszMzFqr3mGHS4iIfwKHAMeXWhszMzNriz4FBNmGwPL1bCjpLElPSLqrkDZC0jWS7s9/hxfWHSVpjqT7JG1fSB8naVZed7Ik5fTlJF2Q02+WNKaB4zIzM1vq1BUQSPqLpBsKjxnAzcCP6yxnCjCpKu1I4NqI2AC4Nj9H0kbAZGDjvM/P8y2YAU4DDgA2yI9KnvsDz0bE+sBJwPfrrJeZmZlRf6fCM6qevwjcERH317NzRNxQ41f7zsCEvHw2MA04IqdPzVMlPyRpDrC5pLnAShExHUDSOcAuwNV5n2NyXhcBp0hSRLw5gZKZmVkzjDnyyprph41dzH411s09YYdmV6lP1KrvzBwQXBERm+Tnz0XEKoX1z0bEcEmnADdFxHk5/UzSl/5c4ISI2C6nbwUcERE75ksRkyJifl73APChiHiqRj0OILUy0NHRMW7q1Kmd6jrr0edrHkPHUFjwcu3jGzty5Z5PQh0WLVrEsGHDSsnLZfTv/AdiGb19b5T1vgC/3i6j/+Y/kN4XEydOnBkR42utq3cegouBkyLiL4W0rYCDI2K3umtSH9VIqx7yWEzvbp/OiRGnA6cDjB8/PiZMmNBpm1oRHaRo78RZtU/Z3L0659MX06ZNo1adyuQy+kf+A7GM3r43ynpfgF9vl9F/8x8s74t6OxVuA/ytKm06MLGBshdIWgMg/30ip88HRhe2GwU8ltNH1UhfYh9JQ4CVgWcaqJuZmdlSpd6A4BVghaq0YcC/Gij7cmDfvLwvcFkhfXIeObAOqfPgLRHxOLBQ0hZ5dME+VftU8toNuM79B8zMzOpXb0DwR+CXklYCyH9PAf5Qz86Szie1KGwoab6k/YETgI9Luh/4eH5ORMwGLgTuzvkfFBGv56wOJHVwnAM8QOpbAHAmsGrugHgoecSCmZmZ1afeUQaHAecBz0h6BhhB+jLeu56dI2LPLlZt28X2xwHH1UifAWxSI/0VYPd66mJmZmad1Tt18bPADnnK4tHAvDxboZmZmQ0C9Y4y+AQwNyL+Afwzp20IrBUR1zSxfmZmZtYC9fYhOBVYWJW2MKebmZnZAFdvQPDO3Mu/6HHgXSXXx8zMzNqg3oDgQUkfq0qbADxUbnXMzMysHeodZXAMcHGeRvgBYD3gs/lhZmZmA1xdLQQRcRnwCdLkRDvkv9vndDMzMxvg6m0hICJuAW5pYl3MzMysTXpsIZA0RtIUSY9KejX/PVvSuq2ooJmZmTVftwGBpPcCtwLvBP4L+Pf8d3VgRl5vZmZmA1xPlwxOAE6NiP+uSp8i6XvAD4CdmlIzMzMza5meAoKteesugtVOxMMOzczMBoWe+hAsS9e3OP5XXm9mZmYDXE8Bwd/peq6B/YAZpdbGzMzM2qKnSwb/Dfwx38joItJ0xWuQbjW8L7B9c6tnZmZmrdBtC0FE/I00IdH7gGuBe/Pf9wGT8nozMzMb4HqcmCgipgNbSxoKjACejYiXml4zMzMza5nezFT4MvBoE+tiZmZmbVLv3Q7NzMxsEHNAYGZmZl0HBJJ+WFj+WGuqY2ZmZu3QXQvBAYXlS5tcDzMzM2uj7joV3iHpIuBuYDlJ3621UUR8qyk1MzMzs5bpLiDYjdRKsDYgYHSNbaIZlTIzM7PW6jIgiIgngO8BSBoSEV1NYdxneQbECwpJ6wLfAlYBvgA8mdOPjoir8j5HAfsDrwNfjYg/5vRxwBRgKHAVcHBEOGAxMzOrQ13zEETEZyUNJ93qeCRpPoIrIuKZRgqPiPuAzQAkLZvzvYR0/4STIuJHxe0lbQRMBjYG1gT+JOndEfE6cBqpReMmUkAwCbi6kfqZmZktLeoadijpw8ADwJeATYEvAnNyelm2BR6IiIe72WZnYGpEvBoRDwFzgM0lrQGsFBHTc6vAOcAuJdbNzMxsUKt3HoKfAP8ZER+JiD0jYkvgQODkEusyGTi/8PzLku6UdFZunYDUOjGvsM38nDYyL1enm5mZWR1Uz2V2Sc8Cq0bEG4W0ZYGnImJ413vWWQnp7cBjwMYRsUBSB/AUqdPiscAaEfE5SacC0yPivLzfmaTLA48Ax0fEdjl9K+DwiNipRlkHkIdUdnR0jJs6dWqn+sx69Pma9ewYCgtern0MY0eu3JtD7tKiRYsYNmxYKXm5jP6d/0Aso7fvjbLeF+DX22X03/wH0vti4sSJMyNifK119d7L4H7SL/jfFtJ2J11GKMO/AbdGxAKAyl8ASb8CrshP57PkaIdRpEBifl6uTu8kIk4HTgcYP358TJgwodM2+x15Zc1KHjZ2MSfOqn3K5u7VOZ++mDZtGrXqVCaX0T/yH4hl9Pa9Udb7Avx6u4z+m/9geV/Ue8ngEOAUSTdJukDSzcDPga+WUgvYk8LlgtwnoGJX4K68fDkwWdJyktYBNgBuiYjHgYWStpAkYB/gspLqZmZmNujVO8rgb5LWA3Yg9e7/PXBVo6MMACQtD3yc1FGx4geSNiNdMphbWRcRsyVdSJosaTFwUB5hAKlPwxTSsMOr8QgDMzOzuvXm9sfPAueVXYGIeAlYtSpt7262Pw44rkb6DGCTsus3kI3pphmrVhPX3BN2aHaVzMysn/LdDs3MzMwBgZmZmTkgMDMzM3oREEhau5kVMTMzs/bpTQvBbQCSyhpqaGZmZv1Et6MMJM0EZpKCgWVz8jGUO2WxmZmZtVlPLQS7Af8HrA0sL+lWYDlJEyWVN/eimZmZtVVPAcEyEXFRRBwJLCTdbVDAV4DbJd3f7AqamZlZ8/U0MdFvJa1FmhnwHcBw4JWI+BSApBFNrp+ZmZm1QLcBQUR8SNIQYCxwI3AKsKKk04Bb86Ph6YvNzMysvXqcujgiFgO3SXotIraW9BwwDRgH7AFs19QampmVqLdTeoOn9balQ933MgC+lv9GRFwAXNCE+piZmVkb1D0PQURMyYvrNqcqZmZm1i69nro43/XQzMzMBhHfy8DMzMwcEJiZmZkDAjMzM8MBgZmZmeGAwMzMzHBAYGZmZjggMDMzMxwQmJmZGQ4IzMzMDAcEZmZmhgMCMzMzox8EBJLmSpol6XZJM3LaCEnXSLo//x1e2P4oSXMk3Sdp+0L6uJzPHEknS1I7jsfMzGwgantAkE2MiM0iYnx+fiRwbURsAFybnyNpI2AysDEwCfi5pGXzPqcBBwAb5MekFtbfzMxsQOsvAUG1nYGz8/LZwC6F9KkR8WpEPATMATaXtAawUkRMj4gAzinsY2ZmZj1Q+v5sYwWkh4BngQB+GRGnS3ouIlYpbPNsRAyXdApwU0Scl9PPBK4G5gInRMR2OX0r4IiI2LFGeQeQWhLo6OgYN3Xq1E51mvXo8zXr2jEUFrxc+zjGjly5ziPu3qJFixg2bFgpefX2OMo6Bij3ONpVxmA4hrLLGAz/U4Pl/e0y+k/+A+l9MXHixJmF1vglDCmtVn23ZUQ8JumdwDWS7u1m21r9AqKb9M6JEacDpwOMHz8+JkyY0Gmb/Y68smbhh41dzImzap+yuXt1zqcvpk2bRq069UVvj6OsY4Byj6NdZQyGYyi7jMHwPzVY3t8uoz5juny9X+fEG1+suW7uCTv0qozB8L6AfnDJICIey3+fAC4BNgcW5MsA5L9P5M3nA6MLu48CHsvpo2qkm5mZWR3aGhBIWkHSipVl4BPAXcDlwL55s32By/Ly5cBkSctJWofUefCWiHgcWChpizy6YJ/CPmZmZtaDdl8y6AAuySMEhwC/jYg/SPo7cKGk/YFHgN0BImK2pAuBu4HFwEER8XrO60BgCjCU1K/g6lYeiJmZ2UDW1oAgIh4E3lcj/Wlg2y72OQ44rkb6DGCTsutoZma2NGh7HwIzMzNrPwcEZmZm5oDAzMzMHBCYmZkZDgjMzMwMBwRmZmaGAwIzMzPDAYGZmZnhgMDMzMxwQGBmZmY4IDAzMzMcEJiZmRkOCMzMzAwHBGZmZoYDAjMzM8MBgZmZmeGAwMzMzHBAYGZmZjggMDMzMxwQmJmZGQ4IzMzMDAcEZmZmBgxpdwWWVmOOvLJm+mFjF7NfjXVzT9ih2VUyM7OlmFsIzMzMrL0BgaTRkv4s6R5JsyUdnNOPkfSopNvz45OFfY6SNEfSfZK2L6SPkzQrrztZktpxTGZmZgNRuy8ZLAYOi4hbJa0IzJR0TV53UkT8qLixpI2AycDGwJrAnyS9OyJeB04DDgBuAq4CJgFXt+g4zMzMBrS2BgQR8TjweF5eKOkeYGQ3u+wMTI2IV4GHJM0BNpc0F1gpIqYDSDoH2AUHBFaH3vbnAPfpMLPBp9/0IZA0Bng/cHNO+rKkOyWdJWl4ThsJzCvsNj+njczL1elmZmZWB0VEu+uApGHA9cBxEXGxpA7gKSCAY4E1IuJzkk4FpkfEeXm/M0mXBx4Bjo+I7XL6VsDhEbFTjbIOIF1aoKOjY9zUqVM71WfWo8/XrGfHUFjwcu1jGDty5d4ccq/L6G3+rSqjK4sWLWLYsGGl5dfMMlrxendlIJ0nGBz/U369l64yBsvneVd6e54mTpw4MyLG11rX7j4ESHob8DvgNxFxMUBELCis/xVwRX46Hxhd2H0U8FhOH1UjvZOIOB04HWD8+PExYcKETtt01Ux82NjFnDir9imbu1fnfLrT2zJ6m3+ryujKtGnTqHVuy1RWGa14vbsykM4TDI7/Kb/eS1cZg+XzvCtlvhbtHmUg4Ezgnoj4cSF9jcJmuwJ35eXLgcmSlpO0DrABcEvui7BQ0hY5z32Ay1pyEGZmZoNAu1sItgT2BmZJuj2nHQ3sKWkz0iWDucAXASJitqQLgbtJIxQOyiMMAA4EpgBDSZ0J3aHQzMysTu0eZXAjUGu+gKu62ec44Lga6TOATcqrnZmZ2dKj34wyMDMzs/ZxQGBmZmZt70NgZmb9lG/CtnRxC4GZmZk5IDAzMzMHBGZmZoYDAjMzM8OdCs2sH+mqExu4I5tZszkgMDMbgDwCwMrmgMBskPAXhJk1wn0IzMzMzAGBmZmZOSAwMzMzHBCYmZkZ7lRoZmZt4mGm9WtFp2G3EJiZmZkDAjMzM3NAYGZmZjggMDMzMxwQmJmZGQ4IzMzMDA87tH7Ow5LMzFrDLQRmZmbmgMDMzMx8ycCsJXxrYjPr7wZVC4GkSZLukzRH0pHtro+ZmdlAMWgCAknLAqcC/wZsBOwpaaP21srMzGxgGDQBAbA5MCciHoyI14CpwM5trpOZmdmAMJj6EIwE5hWezwc+1Ka6LDV8bdysM78vbCBSRLS7DqWQtDuwfUR8Pj/fG9g8Ir5Std0BwAH56YbAfb0oZjXgqRKq6zIGRhmD4RhcRv/J32X0rzIGwzH0pYy1I2L1WisGUwvBfGB04fko4LHqjSLidOD0vhQgaUZEjO9b9VzGQCtjMByDy+g/+buM/lXGYDiGsssYTH0I/g5sIGkdSW8HJgOXt7lOZmZmA8KgaSGIiMWSvgz8EVgWOCsiZre5WmZmZgPCoAkIACLiKuCqJhbRp0sNLmPAljEYjsFl9J/8XUb/KmMwHEOpZQyaToVmZmbWd4OpD4GZmZn1kQMCMzNrG0krtbsOljgg6ANJK7S7DmbWN5I+3e46lEXS2m0se82SsrpN0uSS8rIGOCDohqSRksbnYYxIeqek/wHuL7GMIZJ2kvSN/NhRUqmdPSWtno9jlTLzLeS/r6RbJb2YHzMk7dOMsppJ0kRJF0uanR8XSZpQchlDJCkvj5a0m6T3l5T3B6oe75c0uuc9+1TWhpJOlHRlfvxI0oYl5f3lwvLGZeRZZR9Jf5C0bhPyBkDS8pLeVni+oaSvSfpUyUVdK+nIsj8z6nRTSfl8DNhD0jWS1i8pz5okjZW0e35sUnLeh+V76lSnryrpzJLK2F7SbjXS95L08YYLiAg/ajyAQ4AngenArcC+wNPAScAaJZWxJmmmxGk5358A1+e0NUsq4/PAE/k4/gn8e8nnaR/gNmAisDKwCukNPhPYp8RyFgIv5MfCwvOXgMUl5L8D8BDwWeB9wGbA54AHgU+WdAxfAJ4BHsnL/yDdc+M+4IgS8v9zjccdwD3AZiW+Fh8GHgeOId0vZBfgO6SJwLYoIf9bay2X/H+7Sz4v/02a6W1E5VFS/jcAG+Tl9fPr/jPgWuD4Eo9jxfzZcQewdTPOVTdlzys5v0nAAuAK0hwylwOXl5T3yvlz9gHgEuDSvPxnYKWSyjgduB3YspD2n/lz5ZCSyrgJWL1G+ruA6Q3n38p/oIH0AO6ufDgAawGvlfFhV1XGlFr/KMBXgbNLKuOuyj8QsG4Z/zRV+d8EjKmRPga4qYmvz4rAEfkL+8QS8psGvK9G+qbA9SXVeTYwPP8/vQisltOXB2Y38VyNB24oMb+rgQk10rcBri4h/2JAcFsTz8v7gOeBuflD+yHgwZLynlVYPhY4NS+/vbiuxGMZBzyX3+93ArOAO5t17nKZj5SY14bAdcBFpB8X21QeJeV/MvAjYJlC2jLAD4CflXgcHyH9gDyXNFnebynpB2TOv8vXtIzXe1DNQ1CyVyLiGYCIeETSPyKirCayii0iYr/qxIg4WVJv7rHQndci4smc74OSlisp34qVImJudWJEzG1GZ6F82eMQUsvEb4EPRsTTJWT9roi4ozoxIu6U1FFC/pBei2eBZyXNiYinchkvSXqtpDI6iYgZkoaVmOV6ETGtRjnXSypjTPQqknYlfWCvVN3MHhEXN5J5fg98E9gN2Csirmgkvy4Ux3N/DPghQES8JumNMguS9DHgp8AZpFvAl5a/pJ+x5LG8uYrUGlhGGScA/w4cFhFXl5FnDdsBm0bEm+cmIt6QdDQpeCrLXaRAYBLpHB0WEY+XmP87JA2JiMXFxHx5amijmTsg6NooSScXnr+z+DwivlpCGS93s+6lEvKHzscxquTj6O4YulvXK5JWAw4D9gDOAt4fEc+XlT/pF3tf1vXG0NxfYBng7XlZ+fGOksroJAc0ZU44srCbdWWcq+tJXxCQmt53KqwLoKGAgPQL+nfAByKitP/R6jIk/Qh4lHTJ4P/gzYC2NJKmku70+h8RUeYXW8WMPq7rjddJ7+dXi4n5evzkiPhNCWW8Vv0lCm/OcPtqrR16S9JngO8CvwTWI7VAnSrpH8DXI+KJEoq5GPiVpC9HxIu53BVILSCNvi88MVFXJO3b3fqIOLuEMh4Evl5rFfCDiFivhDKaehySXgLm1FoFrBsRpYzIkPQiqU/Hr6nxhRQRP24w/+dIXz6dVgEfjYjhjeSfy5hGN1/METGxwfxr/ZobQWrGPDgift9I/oVyniD1fei0Cvh0RJTVotIUkjYC3k36op4VEX9sQhlDgYOBNUjTqN+R0z9CamE5t6RyvhARvyojr3aRtDLpWvtIUr+Ba4Avkz4bb4+InUso415gT9L/6BKrgPMi4r0llHEZ8NWIeLiQJuBLwDciouFOrLnz6PdIfcMq5awFnAn8d0T8q6H8HRC0j6QpdP8F8dnW1aZv1MOwp+Kbo8FyjqH7c/WdBvPfprv1EXF9I/m3Qo3gL0gdYf9e0q+TrspZstDGg8xDe8i/0eDv58BGpI622wK/j4hjG8mzl+VvGRF/LSmvbkfzRMQ5Deb/e7p/3/17V+t6UcZlwLO89XoMJ/W1ODgibm80/1zGNJoYjNdR/uqVS7cN5vN/EfGJHHBWRmTMKaulywFBF2q8EYJ0z+k/R8R57alV7+Wm9oNIb7izSNcytyL1sD0sImr9uu9N/ocAfyV1/urUJNcKta6plZj3aFKz5Q9LyKt6yFnlf+r2iOiuGb7Rcks7hm7KGA48FyV8oEj6duHpF0lNsG8qIfi7i9SB9HVJywN/iYhxjeRZo4xlgU+TfvX+ISLukrQjcDQwNCLKGmr6s1rJpMssIyOiocvChUB5edIX0Bukz46XoZxAWdKsiBibl5clvSfWauZ7ohkk/SQiDsnLB0fETwvrptTqL9aHMm4r63+nFvch6NqPaqSNAD4jaZOIOLLRAiRNB/4rIq6rse7aiNi20TJIHe9mABsAt5Ca3H9KCgrOACY0mP+onN97JN0J/I0UIEyvdMosQw7Qvlzd4iBp21x+aWOKcxC1O6mJcSRpmFIZdqqRNgLYVNL+tf4P+qqJx4CkbwEXRsS9uYPe1aRhmosl/UdE/KmR/Itf+JJ2aTQAqOG1iHg9l/VSbtYt25nAaNJ77mRJD5OGax4ZEZeWVUhEfKWynI9jL9Lom5uA40oo4m85n8+RhsuK9J6fQgpuyvBmM3cO0h4qOxhoUTC+dWF5X9LnUsWmJZWxco1jeVPDHW7dQtA7OYKdGRGblZDXo6RhT1cBRxWv/5QVCUq6IyLelz8sHo6ItQrrbi/jOHJebycNb/sI6YPvw6RfjBuVlP9epOFbZ5KGCq1OmrdhLeCgiJjZYP4rArsC/0G6vnwJsEdEjGok3zrLXpv0BfuhBvNpyTFImg1sEhEh6QBS0LFdLvPsiNi8xLJujYgPlJVfzvNl0uRilUBgPVI/GAEREQ1/eOdWiE1zT/Z3kL581o+Ifzaad42yhgD7kTrd3kya56CUUUqSTgKGAYdWvjiVRg/9CHip8ou4wTLeABZVnpJ6y7/EW69Hw6OVJP26RvII0hd1KcF48TO7+vO7rP9jSU8Dl9G5LwSkc/W5RvJ3C0Ev5Qi2rOwWAB8l9RC9WdKehTdyWZFa5ZdQSHqqal2Zw5+GAiuRJgBZmTRJTWm9niPiN5KuIAUD9wBvI/1y+VUZzdSkyZtuIQ1HuzGfr11LyLdHEfGwCrPaNaBVx/Ba4ZxvD0zNv7jvUXtmzOut91DuqItaXos8xC0iXlEattyMYOAgUufFa4FJZfXZKdgReHfxPRYRL0g6ELiXNAS4UXc0sxkcuu6PVQnGgYaC8WyZfOlsmcJy5cui0wyGffRwo1/63RkIb962kDSiRvJw0vj32WWVExEvAZ/PH9zXSPqfiPgFtSPAvlhX0uU5v8oy+fk6jWauNO58Y1LP/5tJTYw/jjTevmwbAZuTvvTGAx2k/+GGetZmRwOTgdOA30q6oIQ866I05W8ZQ59adQyvKk37uoA0iUxxpMzyjWYuaRZvfWGvny9FvamEX/B30XVA8KqkB0iX8q5toIz3FOotYL38XMAbEfG+BvIu+hkpEPwo8PvqHyslnKuoFXDnH0ZlBVVta6YuMRiH9ENoJm99dt9aLKqkMppxeetNDgi6NpP0IlZegMo1p2nAgWUXFhGXSLoFmCLpk6RmujIUh+xU+kVE1fNGrAUsR2qCfRSYT5oxrVSSzgA+APxnRExXGnv7HeAOSYdExP81kn9EnAScpDS//Z6kqU3XlHQ4cGlE/KOxI+iyx/YI0tC0zzSafzfHcARwSRnHkB1MmlFudVLw9xBA/r+9rYT8P0UK9uZVpa9NanlqSESs2NW6fElwE+A3NNYvpdYwtsr197KuvUOa4a9p5wq4W9I+UTVaQWnM/b0l5A9pjpcuR5ZEg6NKuiPpPZQTjBMRY8rIpwd7Vyfk/kJPl9Kh130I2kfSHyJiUo30bwDHRkTDk9VI2hkYFRGn5ue3kD7IgzR//v+WUIZIrQQfyY9NSHO3T4+Ib3e3by/K+BpwcqUzWCF9LPDziNiqwfzXBzqiMBxM0qakfgrbRETDTX7qPLSxMizw/ohoeKZCSaMjYl5V2lhScHBEGceQ8zyUJQPlSrB8YyU4aDD/K4CjI+LOqvTxwLcjolbnzFJJ+mJE/LLnLevKazNSv45Pk6ZH/l1EnFJS3k09V5JGkia8eZm3fiR9kHSJcNeIeLSR/HMZj5NatWr++i2jU2lPwXhETG+0jFzOEODfSJelIE2B/8coaRSUpC2AE0ifr8eSpkhejXSZYp+I+END+TsgqE3S4RHxg7y8e/GLMzfrlxnlN42kv5KGnM3Lz28njfVdAfh1lDOSoVLWKGBLUlCwI7BqRKxSVv7N1M0H6wdJH6w7NrHsUmZkU5ro6hekX+2Lc1oHcCLwnogY33Bl6TQssGIEqT/BMRFRa9Ki3uR/V0TU/HWuwhC1/kzSu0mXb/YkBX0XkGar63bejj6U05JzpTQ98sakL+3ZDV5Oqc679I6jNcqoFYw/Q/q/3SMiDiqhjDVJN0t6nNRSJuD9pBsPTYyIhltsJM0gtTCtTLqZ0r9FxE25peP8RvtiOCDoQvGftPoftsQeo9/qZnVECZOlSPp7RHyw8PyUiPhyXr4pIrZoMP+vk67nb0m6lv9X0gQjfyXNAldKx8VC34eaosEJUlrxwZp7Zx9Ek2Zky52YTiDPTAiMBQ4ldcQ8razXopvyRwB/avS9oXSfh5q3we1uXX+Se87/hdSDfU5OezBKmK2uqpzBcK5ua3anwqryNqMJLTZKE83dHhE/qUr/KjAuIrqd0KvOMt4cGSbpnijMsFjGeXQfgq6pi+Vaz/uq1rzvy5OmpVyV1CTUqCWm3K0EA9nqJeT/n8DhwNei3Jt4VPsw6Trp+aTOi2V3runu8kzDNw3JzuWtGdk+D3yDNCPbzlHCjGy5I+cXJR0M/Im3bkc8v9G86yz/GVX3auubv6vGlLyS9ic1Ww8E/4/UQvBnSX8gTfXcjA5hg+FcldZK2ZUuWmwU5c5Q2Iqb1RWD+urZCRv+de+AoGvVsxR2ta7vBUScWFlWGkN+MGkCkKmkZt4y3NzFB8YXSb31G/V8RFxUQj49eRfwcdIb+j+AK0lNZGWN+GjFB+u68daMbGdQ8oxsSjfO+T5pCNUk4JPA1UqzppU26VE35X+MFPA06hDgEqW5JyrnfjwpeGrJUNBGRcQlpGNYAdgF+BrQIek0UgfPhjrBFhzCwD9XpU1g1o17SS02OxVabL5WchmtuFnd+yS9QJ6vIS+Tnzfe58yXDGqT9DrpF3xxogzy83dERClDVXIz66GkGcbOBn4aJQ7Zk/ROUm/zV3lrGMw40siAXSJiQYP5zwe67AXcjB7CSrPj7Umahvm7EVFr+tbe5tlBmsjnNWp8sEYJY8ibdempkN+DwM+BnxT6EGyW0x6OiD1LKqc4LLBiBKlFYp+IKKX3uaSJvNXTf3Yrgppmyu/13UnXrD9Wct6D6lyVTWlY92TS5bRKi80ZEdHw0OtCGU2/WV2zOSBoI0k/JA2xOh04NSIW9bBLI2VVOgVBiR8YuYfwL7paX0YP4UJZywE7kIKBMaTr8GeV0dO5UEbTPlgLQSZQ/oxskkZ1dXmgVutHA+VUd4wL0rCnsm4TbdYUhRabPYGPkX6EldJio9qzIb4pBsLN6hwQtE/uePQqsJglf3GVNmVns7Wih3Au52zSF/XVpJnx7mp2mWY2eDWzxWagckBgDWlVD+EcPFV+gQ7I4MnMBi91fyvqiIhzW1aZPnJAYA2RNKJFnYLMzPotNflW1K3ggMDMzKxEefht5VbUdwPHVU961h/1+4jFzMxsIFDnW1HvFiXdiroVHBCYmZk1SM2/FXXT+ZKBmZlZg3LH5yeAJ6nd8bnRW1E3nVsIzMzMGlfaJEft4hYCMzMzcwuBmZlZoyQtpPZ9bgbMXCluITAzMzOWaXcFzMzMrP0cEJiZmZkDAjMzM3NAYGYlkDRX0nbtroeZ9Z0DAjMbsPJUsWZWAgcEZrYESaMlXSzpSUlPSzpF0nqSrsvPn5L0G0mr5O3PBdYCfi9pkaTDc/oWkv4m6TlJd0iaUChjHUk3SFoo6U+STpV0XmH9v0uanfedJum9hXVzJR0h6U7gRUnfkPS7qmP4maSfNPE0mQ06DgjM7E2SlgWuAB4GxgAjgamksdTHA2sC7wVGA8cARMTewCPAThExLCJ+IGkkcCXwPWAE8HXgd5JWz0X9FrgFWDXns3ehDu8GzgcOAVYHriIFG28vVHVPYAdgFeA8YFIhQBkC7AH0+/vPm/UnDgjMrGhz0pf+NyLixYh4JSJujIg5EXFNRLwaEU8CPwa26SafzwBXRcRVEfFGRFwDzAA+KWkt4IPAtyLitYi4Ebi8sO8ewJW5vH8BPwKGAh8pbHNyRMyLiJcj4nHgBmD3vG4S8FREzGz4bJgtRRwQmFnRaODhiFhcTJT0TklTJT0q6QXSr/LVuslnbWD33OT/nKTngI8Ca5ACjmci4qXC9vMKy2uSWigAiIg38vqRXWwPcDYpCCH/deuAWS85IDCzonnAWjU66x1PmpZ10zwF62dIlxEqqqc8nQecGxGrFB4rRMQJwOPACEnLF7YfXVh+jBRQACBJef2j3ZR3KbCppE2AHYHf9HyoZlbkgMDMim4hfWGfIGkFSe+QtCWwIrAIeC73D/hG1X4LgHULz88DdpK0vaRlcz4TJI3K94mfARwj6e2SPgzsVNj3QmAHSdtKehtwGPAq8LeuKh0RrwAXkfsmRMQjDZwDs6WSAwIze1NEvE76cl6f1FFwPuma/neADwDPkzoLXly16/HAN/Plga9HxDxgZ+Bo0v3h55GCiMpnzl7Ah4GnSR0PLyB96RMR95FaIH4GPJXrs1NEvNZD9c8GxuLLBWZ94psbmVnbSboAuDcivt1AHmsB9wLviogXSquc2VLCLQRm1nKSPpjnNlhG0iRSa8KlDeS3DHAoMNXBgFnfeJYvM2uHd5EuO6xKuixxYETc1peMJK1A6sPwMGnIoZn1gS8ZmJmZmS8ZmJmZmQMCMzMzwwGBmZmZ4YDAzMzMcEBgZmZmOCAwMzMz4P8D7NMooHmdNokAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.plot(x='cat', y='count', kind='bar', legend=False, grid=True, figsize=(8, 5))\n",
    "plt.title(\"Number of articles per category\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('category', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '# of categories')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "rowsums = df.iloc[:,2:].sum(axis=1)\n",
    "x=rowsums.value_counts()#plot\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x.index, x.values)\n",
    "plt.title(\"Multiple categories per comment\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of categories', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of comments that are not labelled:\n",
      "0.09466671442386905\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of comments that are not labelled:')\n",
    "print(len(df[(df['classes_target'].str.len()==0)]) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = df.body.dropna().map(lambda x: \" \".join(x)).str.len()\n",
    "lens.hist(bins = np.arange(0,5000,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = re.sub(r'\\d+ min read', '', str(txt), flags=re.IGNORECASE)\n",
    "    txt = re.sub(r'by reuters staff', '', str(txt), flags=re.IGNORECASE)\n",
    "    ### separate sentences with '. '\n",
    "    txt = re.sub(r'\\.(?=[^ \\W\\d])', '. ', str(txt))\n",
    "    ### remove punctuations and characters\n",
    "    txt = re.sub(r'[^\\w\\s]', '', txt) \n",
    "    ### strip\n",
    "    txt = \" \".join([word.strip() for word in txt.split()])\n",
    "    ### lowercase\n",
    "    txt = txt.lower() \n",
    "    ### slang\n",
    "    txt = contractions.fix(txt) \n",
    "    ### tokenize (convert from string to list)\n",
    "    lst_txt = txt.split()\n",
    "    ### stemming (remove -ing, -ly, ...)\n",
    "    \n",
    "    ps = nltk.stem.porter.PorterStemmer()\n",
    "    lst_txt = [ps.stem(word) for word in lst_txt]\n",
    "    ### lemmatization (convert the word into root word)\n",
    "    \n",
    "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    lst_txt = [lem.lemmatize(word) for word in lst_txt]\n",
    "    \n",
    "    lst_txt = [word for word in lst_txt if word not in \n",
    "               stop_words]\n",
    "    ### back to string\n",
    "    txt = \" \".join(lst_txt)\n",
    "    return txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression()):\n",
    "        self.base_classifier=base_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a Binary Relevance classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples, n_labels] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        \"\"\"\n",
    "\n",
    "        # list of individual classifiers\n",
    "        self.models = []\n",
    "       \n",
    "        # for every class label\n",
    "        for label in list(y.columns):\n",
    "            # Check that X and y have correct shape\n",
    "            x_checked, y_checked = check_X_y(X, y[label])\n",
    "            # every classifier is independent of the others\n",
    "            # hence we create a copy of the base classifier instance\n",
    "            base_model = clone(self.base_classifier)\n",
    "            # fit the base model - one model each for Y1, Y2....Y14\n",
    "            basel_model = base_model.fit(x_checked, y_checked)\n",
    "            # add the fitted model list of individual classifiers\n",
    "            self.models.append(base_model)\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i=0\n",
    "        # list of individual classifier predictions\n",
    "        preds = []\n",
    "        \n",
    "        # predict against each fitted model - one model per label\n",
    "        for model in self.models:\n",
    "            pred = model.predict(X)\n",
    "            # add the prediction to the dataframe\n",
    "            preds.append(pd.DataFrame({'Class'+ str(i+1): pred}))\n",
    "            i+=1\n",
    "        \n",
    "        # dataframe with predictions for all class labels\n",
    "        all_preds = pd.concat(preds, axis=1)\n",
    "        # standard sklearn classifiers return predictions as numpy arrays\n",
    "        # hence convert the dataframe to a numpy array\n",
    "        return all_preds.to_numpy()\n",
    "    \n",
    "\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i = 0\n",
    "        \n",
    "        for model in self.models:\n",
    "            # Call predict_proba of the each base model\n",
    "            pred = model.predict_proba(X)\n",
    "            # Add the probabilities of 1 to the dataframe\n",
    "            all_preds['Class'+str(i+1)] = [one_prob[1] for one_prob in pred]\n",
    "            i+=1\n",
    "        \n",
    "        #return probabilities\n",
    "        return all_preds.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_test, y_pred):\n",
    "    # y_pred is a numpy array, y_test is a dataframe\n",
    "    # to compare the two, convert to a single type\n",
    "    y_test = y_test.to_numpy()\n",
    "    \n",
    "    # shape of test and preds must be equal\n",
    "    assert y_test.shape == y_pred.shape\n",
    "    i=0\n",
    "    # list of scores for each training sample\n",
    "    scores = []\n",
    "    \n",
    "    # for each test sample\n",
    "    while i < len(y_test):\n",
    "        count=0\n",
    "        # count the number of matches in the sample\n",
    "        # y_test[i] -> row values in test set (true values)\n",
    "        # y_pred[i] -> row values in predictions set (predicted values)\n",
    "        for p, q in zip(y_test[i], y_pred[i]):\n",
    "            if p == q:\n",
    "                count += 1\n",
    "\n",
    "        # accuracy score for the sample = no. of correctly predicted labels/total no. of labels\n",
    "        scores.append(count / y_pred.shape[1])\n",
    "        i+=1 \n",
    "\n",
    "    # final accuracy = avg. accuracy over all test samples =\n",
    "    # sum of the accuracy of all training samples/no. of training samples\n",
    "    return round((sum(scores)/len(y_test)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifierUS(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression(max_iter=20000)):\n",
    "        self.base_classifier=base_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a Binary Relevance classifier with Under sampling from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        \"\"\"\n",
    "\n",
    "        # list of individual classifiers\n",
    "        self.models = []\n",
    "        \n",
    "        # for each class label\n",
    "        for label in list(y.columns):\n",
    "            \n",
    "            X_cp = X.copy()\n",
    "            # pick the column values for the label\n",
    "            y_cp = y[label]\n",
    "            \n",
    "            # sampling is done on both X and y, hence join the two dataframes\n",
    "            X_y_data = pd.concat([X_cp, y_cp], axis=1)\n",
    "            \n",
    "            # counters for 0 values and 1 values\n",
    "            n_val0, n_val1 = 0,0\n",
    "            \n",
    "            j=0\n",
    "            # for each sample\n",
    "            while j<len(X_y_data):\n",
    "                # if value for the label is 0\n",
    "                if(X_y_data.iloc[j][label] == 0):\n",
    "                    n_val0+=1\n",
    "                else:\n",
    "                    # value 1\n",
    "                    n_val1+=1\n",
    "                j+=1\n",
    "            \n",
    "            # under sample the majority class\n",
    "            # randomly pick samples from majority class equal to the number of samples in the minority class\n",
    "            # both the classes will have the same number of samples\n",
    "            if n_val0 > n_val1:\n",
    "                # majority 0 values\n",
    "                val1 = X_y_data[X_y_data[label]==1]\n",
    "                val0 = X_y_data[X_y_data[label]==0].sample(n_val1)\n",
    "                \n",
    "                X_y_data = pd.concat([val0, val1], axis=0)\n",
    "            \n",
    "            elif n_val1 > n_val0:\n",
    "                # majority 1 values\n",
    "                val1 = X_y_data[X_y_data[label]==1].sample(n_val0)\n",
    "                val0 = X_y_data[X_y_data[label]==0]\n",
    "                \n",
    "                X_y_data = pd.concat([val0, val1], axis=0)\n",
    "            \n",
    "            # split back into X and y\n",
    "            X_cp = X_y_data.iloc[:, :-1]\n",
    "            y_cp = X_y_data.iloc[:, -1]\n",
    "            \n",
    "            base_model = clone(self.base_classifier)\n",
    "            # fit the base model - one model each for Y1, Y2....Y14\n",
    "            a, b = check_X_y(X_cp, y_cp)\n",
    "            base_model.fit(a, b)\n",
    "            # list of individual classifiers classifiers\n",
    "            self.models.append(base_model)\n",
    "\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i=0\n",
    "        # list of individual classifier predictions\n",
    "        preds = []\n",
    "        \n",
    "        # for every fitted model\n",
    "        for model in self.models:\n",
    "            # predict for X\n",
    "            pred = model.predict(X)\n",
    "            # add to the list of predictions\n",
    "            preds.append(pd.DataFrame({'Class'+ str(i+1): pred}))\n",
    "            i+=1\n",
    "        \n",
    "        # store predictions for each label in a single dataframe\n",
    "        all_preds = pd.concat(preds, axis=1)\n",
    "        # standard sklearn classifiers return predictions as numpy arrays\n",
    "        # hence convert the dataframe to a numpy array\n",
    "        return all_preds.to_numpy()\n",
    "    \n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i = 0\n",
    "        \n",
    "        for model in self.models:\n",
    "            # Call predict_proba of the each base model\n",
    "            pred = model.predict_proba(X)\n",
    "            # Add the probabilities of 1 to the dataframe\n",
    "            all_preds['Class'+str(i+1)] = [one_prob[1] for one_prob in pred]\n",
    "            i+=1\n",
    "        \n",
    "        #return probabilities\n",
    "        return all_preds.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierChains(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression(max_iter=20000), order=None, classes=None):\n",
    "        self.base_classifier=base_classifier\n",
    "        self.order = order\n",
    "        self.classes = classes\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a Classifier Chain from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples, n_labels] \n",
    "            The target values (class labels) as integers or strings.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # check the order parameter\n",
    "        if self.order is None:\n",
    "            # default value - natural order for number of labels\n",
    "            self.order = list(range(y.shape[1]))\n",
    "        elif self.order == 'random':\n",
    "            # random order\n",
    "            self.order = list(range(y.shape[1]))\n",
    "            random.shuffle(self.order)\n",
    "        else:\n",
    "            # order specified\n",
    "            if(len(self.order)==y.shape[1]):\n",
    "                # expect order from 1, hence reduce 1 to consider zero indexing\n",
    "                self.order = [o - 1 for o in self.order]\n",
    "    \n",
    "        \n",
    "        # list of base models for each class\n",
    "        self.models = [clone(self.base_classifier) for clf in range(y.shape[1])]\n",
    "\n",
    "        # create a copy of X\n",
    "        X_joined = X.copy()\n",
    "       # X_joined.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # create a new dataframe with X and y-in the order specified\n",
    "        # if order = [2,4,5,6...] -> X_joined= X, y2, y4, y5...\n",
    "        for val in self.order:\n",
    "            X_joined = pd.concat([X_joined, y[self.classes[val]]], axis=1)\n",
    "\n",
    "        \n",
    "        # for each ith model, fit the model on X + y0 to yi-1 (in the order specified)\n",
    "        # if order = [2,4,6,....] fit 1st model on X for y2, fit second model on X+y2 for y4...\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            # select values of the class in order\n",
    "            y_vals = y.loc[:, self.classes[self.order[chain_index]]]\n",
    "            # pick values for training - X+y upto the current label\n",
    "            t_X = X_joined.iloc[:, :(X.shape[1]+chain_index)]\n",
    "            check_X_y(t_X, y_vals)\n",
    "            # fit the model\n",
    "            model.fit(t_X, y_vals)\n",
    "\n",
    "\n",
    "            \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # dataframe to maintain previous predictions\n",
    "        pred_chain = pd.DataFrame(columns=[self.classes[o] for o in self.order])\n",
    "        \n",
    "        X_copy = X.copy()\n",
    "        X_joined = X.copy()\n",
    "        \n",
    "        # use default indexing\n",
    "        X_joined.reset_index(drop=True, inplace=True)\n",
    "        X_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        i=0\n",
    "        \n",
    "        # for each ith model, predict based on X + predictions of all models upto i-1\n",
    "        # happens in the specified order since models are already fitted according to the order\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            # select previous predictions - all columns upto the current index\n",
    "            prev_preds = pred_chain.iloc[:, :chain_index]\n",
    "            # join the previous predictions with X\n",
    "            X_joined = pd.concat([X_copy, prev_preds], axis=1)\n",
    "            # predict on the base model\n",
    "            pred = model.predict(X_joined)\n",
    "            # add the new prediction to the pred chain\n",
    "            pred_chain[self.classes[self.order[i]]] = pred\n",
    "            i+=1\n",
    "\n",
    "        # re-arrange the columns in natural order to return the predictions\n",
    "        pred_chain = pred_chain.loc[:, [self.classes[j] for j in range(0, len(self.order))]]\n",
    "        # all sklearn implementations return numpy array\n",
    "        # hence convert the dataframe to numpy array\n",
    "        return pred_chain.to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Function to predict probabilities of 1s\n",
    "    def predict_proba(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # dataframe to maintain previous predictions\n",
    "        pred_chain = pd.DataFrame(columns=[self.classes[o] for o in self.order])\n",
    "        # dataframe to maintain probabilities of class labels\n",
    "        pred_probs = pd.DataFrame(columns=[self.classes[o] for o in self.order])\n",
    "        X_copy = X.copy()\n",
    "        X_joined = X.copy()\n",
    "        \n",
    "        # use default indexing\n",
    "        X_joined.reset_index(drop=True, inplace=True)\n",
    "        X_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        i=0\n",
    "        \n",
    "        # for each ith model, predict based on X + predictions of all models upto i-1\n",
    "        # happens in the specified order since models are already fitted according to the order\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            \n",
    "            # select previous predictions - all columns upto the current index\n",
    "            prev_preds = pred_chain.iloc[:, :chain_index]\n",
    "            # join the previous predictions with X\n",
    "            X_joined = pd.concat([X_copy, prev_preds], axis=1)\n",
    "            # predict on the base model\n",
    "            pred = model.predict(X_joined)\n",
    "            # predict probabilities\n",
    "            pred_proba = model.predict_proba(X_joined)\n",
    "            # add the new prediction to the pred chain\n",
    "            pred_chain[self.classes[self.order[i]]] = pred\n",
    "            # save the probabilities of 1 according to label order\n",
    "            pred_probs[self.classes[self.order[i]]] = [one_prob[1] for one_prob in pred_proba]\n",
    "            i+=1\n",
    "\n",
    "        # re-arrange the columns in natural order to return the probabilities\n",
    "        pred_probs = pred_probs.loc[:, [self.classes[j] for j in range(0, len(self.order))]]\n",
    "        # all sklearn implementations return numpy array\n",
    "        # hence convert the dataframe to numpy array\n",
    "        return pred_probs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_remove = ['ARS','MXN','OIL','XAU','TRY','INDEX','BTC','TWD','RUB','CHF']\n",
    "df = df.drop(labels=to_remove,axis=1)\n",
    "classes = [cls for cls in classes if cls not in to_remove]\n",
    "df['text_clean'] = df.body.map(lambda x: \" \".join(list(x)) if type(x) is list else \"\" ).map(lambda com : clean_text(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[classes].sum(axis=1)\n",
    "df = df.sample(n=3000)\n",
    "train, test = train_test_split(df[(df[classes].sum(axis=1)>0)], random_state=42, test_size=0.50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.text_clean\n",
    "y_train = train[classes]\n",
    "X_test = test.text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB_pipeline = Pipeline([\n",
    "#                 ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "#                 ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "#                     fit_prior=True, class_prior=None))),\n",
    "#             ])\n",
    "# for category in classes:\n",
    "#     print('... Processing {}'.format(category))\n",
    "#     # train the model using X_dtm & y\n",
    "#     NB_pipeline.fit(X_train, train[category])\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = NB_pipeline.predict(X_test)\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "#     print('Balanced Test accuracy is {}'.format(balanced_accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogReg_pipeline = Pipeline([\n",
    "#                 ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "#                 ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "#             ])\n",
    "# for category in classes:\n",
    "#     print('... Processing {}'.format(category))\n",
    "#     # train the model using X_dtm & y\n",
    "#     LogReg_pipeline.fit(X_train, train[category])\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = LogReg_pipeline.predict(X_test)\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC_pipeline = Pipeline([\n",
    "#                 ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "#                 ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "#             ])\n",
    "# for category in classes:\n",
    "#     print('... Processing {}'.format(category))\n",
    "#     # train the model using X_dtm & y\n",
    "#     SVC_pipeline.fit(X_train, train[category])\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = SVC_pipeline.predict(X_test)\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "vectorizer.fit(train.text_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "br_clf = BinaryRelevanceClassifier(LogisticRegression())\n",
    "# fit\n",
    "br_clf.fit(vectorizer.transform(train.text_clean).toarray(), train[classes])\n",
    "# predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape: (1208, 8)\n"
     ]
    }
   ],
   "source": [
    "y_pred = br_clf.predict(vectorizer.transform(test.text_clean).toarray())\n",
    "\n",
    "print(\"y_pred.shape: \" + str(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Binary Relevance Classifier: 0.85969\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Binary Relevance Classifier: \" + str(accuracy_score(test[classes], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train.text_clean).toarray()\n",
    "y_train = train[classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=  13.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=  12.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=  13.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=  11.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=  12.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  22.8s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  22.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  22.8s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  21.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  21.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   5.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   4.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   4.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   4.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   4.7s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   4.1s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   4.1s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   3.8s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   3.8s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   3.7s\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.1min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.2min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.2min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.2min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.2min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.6min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.6min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.7min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.6min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 22.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_classifier': DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9672700000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_folds=5\n",
    "\n",
    "# Set up the parameter grid to search\n",
    "param_grid ={'base_classifier': [DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2),\n",
    "                                 RandomForestClassifier(criterion='entropy'),\n",
    "                                 LogisticRegression(max_iter=20000), GaussianNB(), KNeighborsClassifier(), SVC()] }\n",
    "\n",
    "# Perform the search\n",
    "# Using the custom accuracy function defined earlier\n",
    "tuned_model = GridSearchCV(BinaryRelevanceClassifier(), \\\n",
    "                            param_grid, scoring=make_scorer(accuracy_score), verbose = 2, cv=cv_folds)\n",
    "tuned_model.fit(X_train, y_train)\n",
    "\n",
    "# Print details of the best model\n",
    "print(\"Best Parameters Found: \")\n",
    "display(tuned_model.best_params_)\n",
    "display(tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifierUS(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression(max_iter=20000)):\n",
    "        self.base_classifier=base_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a Binary Relevance classifier with Under sampling from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        \"\"\"\n",
    "\n",
    "        # list of individual classifiers\n",
    "        self.models = []\n",
    "        \n",
    "        # for each class label\n",
    "        for label in list(y.columns):\n",
    "            \n",
    "            X_cp = X.copy()\n",
    "            # pick the column values for the label\n",
    "            y_cp = y[label]\n",
    "            \n",
    "            # sampling is done on both X and y, hence join the two dataframes\n",
    "            X_y_data = pd.concat([X_cp, y_cp], axis=1)\n",
    "            \n",
    "            # counters for 0 values and 1 values\n",
    "            n_val0, n_val1 = 0,0\n",
    "            \n",
    "            j=0\n",
    "            # for each sample\n",
    "            while j<len(X_y_data):\n",
    "                # if value for the label is 0\n",
    "                if(X_y_data.iloc[j][label] == 0):\n",
    "                    n_val0+=1\n",
    "                else:\n",
    "                    # value 1\n",
    "                    n_val1+=1\n",
    "                j+=1\n",
    "            \n",
    "            # under sample the majority class\n",
    "            # randomly pick samples from majority class equal to the number of samples in the minority class\n",
    "            # both the classes will have the same number of samples\n",
    "            if n_val0 > n_val1:\n",
    "                # majority 0 values\n",
    "                val1 = X_y_data[X_y_data[label]==1]\n",
    "                val0 = X_y_data[X_y_data[label]==0].sample(n_val1).reset_index(drop=True)\n",
    "                \n",
    "                X_y_data = pd.concat([val0, val1], axis=0)\n",
    "            \n",
    "            elif n_val1 > n_val0:\n",
    "                # majority 1 values\n",
    "                val1 = X_y_data[X_y_data[label]==1].sample(n_val0).reset_index(drop=True)\n",
    "                val0 = X_y_data[X_y_data[label]==0]\n",
    "                \n",
    "                X_y_data = pd.concat([val0, val1], axis=0)\n",
    "            \n",
    "            # split back into X and y\n",
    "            X_cp = X_y_data.iloc[:, :-1]\n",
    "            y_cp = X_y_data.iloc[:, -1]\n",
    "            \n",
    "            base_model = clone(self.base_classifier)\n",
    "            # fit the base model - one model each for Y1, Y2....Y14\n",
    "            a, b = check_X_y(X_cp, y_cp)\n",
    "            base_model.fit(a, b)\n",
    "            # list of individual classifiers classifiers\n",
    "            self.models.append(base_model)\n",
    "\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i=0\n",
    "        # list of individual classifier predictions\n",
    "        preds = []\n",
    "        \n",
    "        # for every fitted model\n",
    "        for model in self.models:\n",
    "            # predict for X\n",
    "            pred = model.predict(X)\n",
    "            # add to the list of predictions\n",
    "            preds.append(pd.DataFrame({'Class'+ str(i+1): pred}))\n",
    "            i+=1\n",
    "        \n",
    "        # store predictions for each label in a single dataframe\n",
    "        all_preds = pd.concat(preds, axis=1)\n",
    "        # standard sklearn classifiers return predictions as numpy arrays\n",
    "        # hence convert the dataframe to a numpy array\n",
    "        return all_preds.to_numpy()\n",
    "    \n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i = 0\n",
    "        \n",
    "        for model in self.models:\n",
    "            # Call predict_proba of the each base model\n",
    "            pred = model.predict_proba(X)\n",
    "            # Add the probabilities of 1 to the dataframe\n",
    "            all_preds['Class'+str(i+1)] = [one_prob[1] for one_prob in pred]\n",
    "            i+=1\n",
    "        \n",
    "        #return probabilities\n",
    "        return all_preds.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape=(1208, 8)\n"
     ]
    }
   ],
   "source": [
    "brus_clf = BinaryRelevanceClassifierUS()\n",
    "train = train.reset_index()\n",
    "# .\n",
    "brus_clf.fit(pd.DataFrame(vectorizer.transform(train.text_clean).toarray()), train[classes])\n",
    "\n",
    "# predict br_clf.fit(vectorizer.transform(train.text_clean).toarray(), train[classes])\n",
    "y_pred = brus_clf.predict(vectorizer.transform(test.text_clean).toarray())\n",
    "print(\"y_pred.shape=\" + str(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Binary Relevance Classifier with Under-sampling: 0.84851\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Binary Relevance Classifier with Under-sampling: \" + str(accuracy_score(test[classes], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total= 1.3min\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total= 1.3min\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total= 1.3min\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total= 1.2min\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total= 1.2min\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total= 1.3min\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total= 1.3min\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total= 1.5min\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total= 1.3min\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total= 1.3min\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total= 1.2min\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total= 1.3min\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total= 1.3min\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total= 1.3min\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total= 1.3min\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total= 1.2min\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total= 1.2min\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total= 1.2min\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total= 1.2min\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total= 1.3min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.7min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.7min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.6min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.6min\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total= 1.7min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.1min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.0min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.0min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.1min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 43.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_classifier': DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9474940000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_folds=5\n",
    "\n",
    "# Set up the parameter grid to search\n",
    "param_grid ={'base_classifier': [DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2),\n",
    "                                 RandomForestClassifier(criterion='entropy'),\n",
    "                                 LogisticRegression(max_iter=20000), GaussianNB(), KNeighborsClassifier(), SVC()] }\n",
    "\n",
    "# Perform the search\n",
    "# Using the custom accuracy function defined earlier\n",
    "tuned_model = GridSearchCV(BinaryRelevanceClassifierUS(), \\\n",
    "                            param_grid, scoring=make_scorer(accuracy_score), verbose = 2, cv=cv_folds)\n",
    "tuned_model.fit(pd.DataFrame(vectorizer.transform(train.text_clean).toarray()), train[classes])\n",
    "\n",
    "# Print details of the best model\n",
    "print(\"Best Parameters Found: \")\n",
    "display(tuned_model.best_params_)\n",
    "display(tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Accuracy Scores=====================\n",
      "Binary Relevance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': 0.96544,\n",
       " 'Random Forest': 0.87603,\n",
       " 'Logistic Regression': 0.85969,\n",
       " 'GaussianNB': 0.78084,\n",
       " 'kNN': 0.78663,\n",
       " 'SVM': 0.87676}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Relevance with Under-Sampling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': 0.94888,\n",
       " 'Random Forest': 0.85306,\n",
       " 'Logistic Regression': 0.84478,\n",
       " 'GaussianNB': 0.55484,\n",
       " 'kNN': 0.72982,\n",
       " 'SVM': 0.84975}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================F1 Scores========================\n",
      "Binary Relevance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': 0.9335217964219708,\n",
       " 'Random Forest': 0.5480754771494546,\n",
       " 'Logistic Regression': 0.5137350351091038,\n",
       " 'GaussianNB': 0.4928619393651144,\n",
       " 'kNN': 0.2563575677399216,\n",
       " 'SVM': 0.624425925767581}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Relevance with Under-Sampling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': 0.8970988960046786,\n",
       " 'Random Forest': 0.6946745728064043,\n",
       " 'Logistic Regression': 0.6917307800200806,\n",
       " 'GaussianNB': 0.486136253324379,\n",
       " 'kNN': 0.42653649185806836,\n",
       " 'SVM': 0.702431033491274}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list of base models\n",
    "X_train = pd.DataFrame(vectorizer.transform(train.text_clean).toarray())\n",
    "y_train = train[classes]\n",
    "X_test = pd.DataFrame(vectorizer.transform(test.text_clean).toarray())\n",
    "y_test = test[classes]\n",
    "base_models = [DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2),\n",
    "               RandomForestClassifier(criterion='entropy'),\n",
    "               LogisticRegression(max_iter=20000), GaussianNB(), KNeighborsClassifier(), SVC()]\n",
    "base_model_names = [\"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"GaussianNB\", \"kNN\", \"SVM\"]\n",
    "\n",
    "# store accuracy scores\n",
    "br_clf_accuracies = dict()\n",
    "br_clfus_accuracies = dict()\n",
    "\n",
    "# store F1 scores\n",
    "br_clf_f1 = dict()\n",
    "br_clfus_f1 = dict()\n",
    "\n",
    "i=0\n",
    "for clf in base_models:\n",
    "    # without undersampling\n",
    "    br_clf = BinaryRelevanceClassifier(clf)\n",
    "    br_clf.fit(X_train, y_train)\n",
    "    br_y_pred = br_clf.predict(X_test)\n",
    "\n",
    "    # find accuracy using custom accuracy function defined\n",
    "    accuracy = accuracy_score(y_test, br_y_pred)\n",
    "    br_clf_accuracies[base_model_names[i]] = accuracy\n",
    "\n",
    "    # find f1 score using sklearn\n",
    "    y_pred_df = pd.DataFrame(br_y_pred)\n",
    "    f1_score_br = metrics.f1_score(y_test, y_pred_df, average='macro')\n",
    "    br_clf_f1[base_model_names[i]] = f1_score_br\n",
    "\n",
    "    \n",
    "    # with undersampling\n",
    "    brus_clf = BinaryRelevanceClassifierUS(clf)\n",
    "    brus_clf.fit(X_train, y_train)\n",
    "    brus_y_pred = brus_clf.predict(X_test)\n",
    "    \n",
    "    # find accuracy using custom accuracy function defined\n",
    "    accuracy_us = accuracy_score(y_test, brus_y_pred)\n",
    "    br_clfus_accuracies[base_model_names[i]] = accuracy_us\n",
    "    \n",
    "    # find f1 score using sklearn\n",
    "    y_pred_df = pd.DataFrame(brus_y_pred)\n",
    "    f1_score_us = metrics.f1_score(y_test, y_pred_df, average='macro')\n",
    "    br_clfus_f1[base_model_names[i]] = f1_score_us\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "print(\"===================Accuracy Scores=====================\")\n",
    "print(\"Binary Relevance\")\n",
    "display(br_clf_accuracies)\n",
    "print(\"Binary Relevance with Under-Sampling\")\n",
    "display(br_clfus_accuracies)\n",
    "\n",
    "print(\"======================F1 Scores========================\")\n",
    "print(\"Binary Relevance\")\n",
    "display(br_clf_f1)\n",
    "print(\"Binary Relevance with Under-Sampling\")\n",
    "display(br_clfus_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f929c34ff50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(br_clf_accuracies.keys()), list(br_clf_accuracies.values()))\n",
    "plt.plot(list(br_clfus_accuracies.keys()), list(br_clfus_accuracies.values()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(['Binary Relevance','Binary Relevance Under-Sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f929c340bd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(br_clf_f1.keys()), list(br_clf_f1.values()))\n",
    "plt.plot(list(br_clfus_f1.keys()), list(br_clfus_f1.values()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(['Binary Relevance','Binary Relevance Under-Sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClassifierChains(classes=classes)\n",
    "# fit\n",
    "cc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1208, 8)\n",
      "(1208, 8)\n",
      "(1207, 8)\n"
     ]
    }
   ],
   "source": [
    "cc_pred = cc.predict(X_test)\n",
    "print(cc_pred.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Classifier Chains: 0.84758\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Classifier Chains: \" + str(accuracy_score(test[classes], cc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  11.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  11.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  10.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  10.3s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  10.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  10.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  14.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  10.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0], total=   9.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  10.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 7, 3, 4, 1, 6, 5, 0], total=   9.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  11.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  10.3s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  10.3s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 7, 2, 0, 4, 3, 6], total=   9.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  10.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  10.3s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  11.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2], total=   9.7s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 4, 0, 7, 1, 3, 6, 2], total=   9.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  10.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  12.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  11.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  10.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  10.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5], total=   9.7s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5], total=   9.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  10.5s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5], total=   9.7s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  10.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7], total=   9.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7], total=   9.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7], total=   9.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  10.5s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0], total=   9.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  10.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  11.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2], total=   9.7s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  10.7s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2], total=   9.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2], total=   9.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  10.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6], total=   9.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  10.5s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6], total=   9.5s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6], total=   9.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  10.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3], total=   9.5s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3], total=   9.7s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  10.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  12.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  10.7s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  10.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  10.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  11.3s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7], total=   9.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7], total=   9.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  11.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  11.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  11.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  10.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  10.9s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  11.5s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1], total=   9.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  10.3s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  11.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  10.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  11.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  10.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  13.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2], total=   9.5s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  11.3s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2], total=   9.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[1, 5, 4, 6, 7, 0, 3, 2], total=   9.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  10.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  10.6s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  11.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  10.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  10.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  10.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  10.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  11.3s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  10.1s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  13.0s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  19.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  18.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  18.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  20.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  23.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  18.7s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  18.8s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  18.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  19.7s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  19.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  21.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  19.8s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  18.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  17.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  18.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  17.6s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  17.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  18.7s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  18.8s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  21.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  18.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  19.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  18.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  19.0s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  17.6s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  20.0s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  26.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  19.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  18.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  17.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  19.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  17.7s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  18.6s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  17.7s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  18.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  18.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  17.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  18.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  17.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  19.0s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  20.8s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  19.6s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  18.0s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  19.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  18.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  21.6s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  23.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  18.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  17.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  17.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  18.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  17.7s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  18.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  17.6s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  18.6s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  17.6s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  18.2s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  20.8s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  19.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  18.0s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  19.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  18.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  18.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  18.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  23.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  21.7s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  17.7s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  18.3s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  18.1s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  18.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  13.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  15.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  14.0s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  16.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  15.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  14.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  15.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  15.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  15.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  14.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  14.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  15.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  15.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  16.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  15.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  16.0s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  16.0s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  17.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  21.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  16.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  18.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  15.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  18.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  15.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  15.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  18.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  23.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  16.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  16.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  16.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  17.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  18.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  17.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  16.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  16.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  14.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  15.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  14.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  15.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  16.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  14.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  15.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  15.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  15.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  16.0s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  14.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  15.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  15.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  17.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  21.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  17.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  17.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  18.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  14.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  15.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  15.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  16.0s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  25.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  21.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  14.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  15.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  14.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  15.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  15.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  14.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  15.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  14.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  15.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  16.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  14.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  15.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  14.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  15.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  16.0s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  15.8s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  15.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  14.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  16.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  15.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  15.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  17.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  22.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  17.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  15.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  15.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  15.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  16.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  14.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  17.7s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  23.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  25.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  16.2s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  17.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  17.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  16.6s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  17.1s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  18.3s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  15.0s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  15.5s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7] \n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  15.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  12.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  11.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  12.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  10.9s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 7, 0, 6, 3, 2, 5, 4], total=  12.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  10.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  11.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  12.2s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  10.9s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 6, 0, 5, 3, 4, 1], total=  11.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  11.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  11.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  11.2s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  12.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 7, 3, 4, 1, 6, 5, 0], total=  11.2s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  14.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  13.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  13.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  11.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 7, 2, 0, 4, 3, 6], total=  12.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  11.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  11.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  12.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  11.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 4, 0, 7, 1, 3, 6, 2], total=  12.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  11.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  12.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  11.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  16.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[5, 1, 6, 2, 7, 4, 3, 0], total=  15.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  11.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  12.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  12.2s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  12.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 4, 3, 7, 1, 6, 2, 5], total=  11.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  11.9s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  12.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  12.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  11.9s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 2, 3, 0, 4, 5, 1, 7], total=  11.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  11.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  11.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  12.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  11.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 7, 6, 1, 4, 5, 0], total=  11.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2] ....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  11.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  12.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  11.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  12.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[7, 6, 3, 1, 0, 5, 4, 2], total=  11.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  12.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  11.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  12.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  11.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 2, 1, 5, 0, 4, 7, 6], total=  11.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  11.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  12.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  11.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  16.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 4, 7, 6, 5, 2, 0, 3], total=  14.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  12.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  12.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  12.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  11.9s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 3, 4, 1, 0, 2, 5, 7], total=  12.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  12.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  12.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  11.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  13.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 5, 3, 2, 0, 4, 7], total=  12.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  14.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  22.2s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  14.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  12.6s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 6, 3, 0, 2, 5, 7, 4], total=  12.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  11.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  12.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  12.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  12.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[2, 6, 7, 0, 5, 3, 4, 1], total=  12.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  12.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  11.9s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  12.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  14.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[6, 1, 2, 7, 0, 5, 4, 3], total=  13.4s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  12.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  13.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  11.2s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  12.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[1, 5, 4, 6, 7, 0, 3, 2], total=  11.5s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  12.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  11.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  12.0s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  11.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[3, 5, 2, 1, 7, 6, 4, 0], total=  12.2s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  11.8s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  13.3s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  12.1s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7] ....\n",
      "[CV]  base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  13.7s\n",
      "[CV] base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7] ....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=GaussianNB(), order=[0, 1, 2, 3, 4, 5, 6, 7], total=  18.3s\n",
      "[CV] base_classifier=KNeighborsClassifier(), order=[1, 7, 0, 6, 3, 2, 5, 4] \n"
     ]
    }
   ],
   "source": [
    "cv_folds=5\n",
    "\n",
    "# generate 20 random orders for class labels \n",
    "rand_orders = [list(range(0, y_test.shape[1])) for i in list(range(1, 20))]\n",
    "\n",
    "for lst in rand_orders:\n",
    "    random.shuffle(lst)\n",
    "\n",
    "# make sure natural order is present\n",
    "rand_orders.append([0,1,2,3,4,5,6,7])\n",
    "\n",
    "# Set up the parameter grid to search\n",
    "param_grid ={'base_classifier': [DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2),\n",
    "                                 RandomForestClassifier(criterion='entropy'),\n",
    "                                 LogisticRegression(max_iter=20000), GaussianNB(), KNeighborsClassifier(), SVC()],\n",
    "            'order': rand_orders,}\n",
    "\n",
    "# Perform the search\n",
    "tuned_model = GridSearchCV(ClassifierChains(classes=classes), \\\n",
    "                            param_grid, scoring=make_scorer(accuracy_score), verbose = 2, cv=cv_folds)\n",
    "tuned_model.fit(X_train, y_train)\n",
    "\n",
    "# Print details\n",
    "print(\"Best Parameters Found: \")\n",
    "display(tuned_model.best_params_)\n",
    "display(tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = tuned_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClassifierChains(base_classifier=best['base_classifier'], order=best['order'],classes=classes)\n",
    "cc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_pred = cc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of Classifier Chains - Best Model: \" + str(accuracy_score(y_test, cc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2),\n",
    "               RandomForestClassifier(criterion='entropy'),\n",
    "               LogisticRegression(max_iter=20000), GaussianNB(), KNeighborsClassifier(), SVC()]\n",
    "base_model_names = [\"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"GaussianNB\", \"kNN\", \"SVM\"]\n",
    "\n",
    "cc_accuracies = dict()\n",
    "cc_f1 = dict()\n",
    "\n",
    "i=0\n",
    "for clf in base_models:\n",
    "    cc = ClassifierChains(clf, order=best['order'],classes=classes)\n",
    "    cc.fit(X_train, y_train)\n",
    "    cc_pred = cc.predict(X_test)\n",
    "    # accuracy score\n",
    "    accuracy = accuracy_score(y_test, cc_pred)\n",
    "    cc_accuracies[base_model_names[i]] = accuracy\n",
    "    # F1 score\n",
    "    cc_f1_score = metrics.f1_score(y_test, pd.DataFrame(cc_pred), average='macro')\n",
    "    cc_f1[base_model_names[i]] = cc_f1_score\n",
    "    i+=1\n",
    "\n",
    "print(\"====================Classifier Chains Accuracy====================\")\n",
    "display(cc_accuracies)\n",
    "print(\"===================Classifier Chains F1 Scores====================\")\n",
    "display(cc_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(br_clf_accuracies.keys()), list(br_clf_accuracies.values()))\n",
    "plt.plot(list(br_clfus_accuracies.keys()), list(br_clfus_accuracies.values()))\n",
    "plt.plot(list(cc_accuracies.keys()), list(cc_accuracies.values()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(['Binary Relevance','BR-Under-Sampling', 'Classifier Chains'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(br_clf_f1.keys()), list(br_clf_f1.values()))\n",
    "plt.plot(list(br_clfus_f1.keys()), list(br_clfus_f1.values()))\n",
    "plt.plot(list(cc_f1.keys()), list(cc_f1.values()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(['Binary Relevance','BR-Under-Sampling', 'Classifier Chains'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
