{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/visnja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/visnja/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "import re\n",
    "import rouge\n",
    "from pymongo import MongoClient\n",
    "import contractions\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "connection=MongoClient(\"mongodb://localhost:27017/crawler.contents\")\n",
    "\n",
    "db=connection.get_database()\n",
    "articles = pd.DataFrame(list(db.contents.find()))\n",
    "\n",
    "\n",
    "articles = articles.drop(columns=['visited','created_at','contentType','date','icon','_id'])\n",
    "articles = articles.dropna(how='any',axis=0)\n",
    "articles[\"text\"] = articles[\"body\"].map(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create stopwords\n",
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "## add words that are too frequent\n",
    "lst_stopwords = lst_stopwords + [\"reuters\",\"staff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning function\n",
    "def utils_preprocess_text(txt, punkt=True, lower=True, slang=True, lst_stopwords=None, stemm=False, lemm=True):\n",
    "    txt = re.sub(r'\\d+ min read', '', str(txt), flags=re.IGNORECASE)\n",
    "    txt = re.sub(r'by reuters staff', '', str(txt), flags=re.IGNORECASE)\n",
    "    ### separate sentences with '. '\n",
    "    txt = re.sub(r'\\.(?=[^ \\W\\d])', '. ', str(txt))\n",
    "    ### remove punctuations and characters\n",
    "    txt = re.sub(r'[^\\w\\s]', '', txt) if punkt is True else txt\n",
    "    ### strip\n",
    "    txt = \" \".join([word.strip() for word in txt.split()])\n",
    "    ### lowercase\n",
    "    txt = txt.lower() if lower is True else txt\n",
    "    ### slang\n",
    "    txt = contractions.fix(txt) if slang is True else txt   \n",
    "    ### tokenize (convert from string to list)\n",
    "    lst_txt = txt.split()\n",
    "    ### stemming (remove -ing, -ly, ...)\n",
    "    if stemm is True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_txt = [ps.stem(word) for word in lst_txt]\n",
    "    ### lemmatization (convert the word into root word)\n",
    "    if lemm is True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_txt = [lem.lemmatize(word) for word in lst_txt]\n",
    "    ### remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_txt = [word for word in lst_txt if word not in \n",
    "                   lst_stopwords]\n",
    "    ### back to string\n",
    "    txt = \" \".join(lst_txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"text_clean\"] = articles[\"text\"].apply(lambda x: utils_preprocess_text(x, punkt=True, lower=True, slang=True, lst_stopwords=lst_stopwords, stemm=False, lemm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo australian dollar riskier currency recovered lost ground dollar monday suffering biggest plunge year end last week amid hefty selloff global bond market greenback weakened broadly early asia trade barely enough trim biggest surge since june friday currency market taken cue global bond market yield surged anticipation accelerated economic recovery aggressive bond selling implies bet global central banker need tighten policy much earlier far forecasting equity commodity also sold debt rout unsettles investor usd direction likely hinge direction also pace global bond move commonwealth bank australia strategist wrote research note bond move trumping economic data driver foreignexchange market yield moving well advance economic fundamental said risk tilted firmer usd week doubt central bank intervene meaningful way yet aussie jumped 06 07754 early asian session monday following 21 plunge friday new zealand dollar strengthened 06 07270 recovering friday 19 slide euro gained 02 120910 dropping 09 end last week since april dollar slipped 01 106415 yen still near sixmonth high 10669 touched friday federal reserve chair jerome powell last week repeated central bank look nearterm inflation spike tighten policy economy clearly improving speak economy friday day usually closely watched monthly payroll data due reserve bank australia hold monthly policy meeting tuesday market widely expecting reinforce forward guidance three year nearzero rate also addressing market dislocation currency bid price 050 gmt description ric last close pct change ytd pct high bid low bid previous change session eurodollar 12095 12070 022 100 12102 12070 dollaryen 1064420 1065700 015 302 1065670 1064000 euroyen 12874 12860 011 143 1288000 1286000 dollarswiss 09075 09086 013 257 09086 09060 sterlingdollar 13983 13923 045 237 13990 13931 dollarcanadian 12693 12740 035 031 12732 12690 aussiedollar 07747 07799 064 073 07757 07706 dollardollar spot tokyo spot europe spot volatility tokyo forex market info boj reporting kevin buckland editing lincoln feast standard thomson trust principle\n"
     ]
    }
   ],
   "source": [
    "print(articles[\"text_clean\"].head()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
