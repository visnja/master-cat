{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics\n",
    "\n",
    "# to avoid future warnings for sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "connection=MongoClient(\"mongodb://localhost:27017/crawler.contents\")\n",
    "\n",
    "db=connection.get_database()\n",
    "articles = pd.DataFrame(list(db.contents.find()))\n",
    "articles = articles.drop(columns=['visited','alternateImageUrl','created_at','contentType','date','icon','publishedAt','source','url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(articles.classes_target.dropna().values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([articles,articles['classes_target'].fillna(\"\").map(lambda x: \",\".join(x)).str.get_dummies(sep=\",\")],axis=1)\n",
    "counts = []\n",
    "for i in classes:\n",
    "    counts.append((i,df[i].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(counts, columns=['cat','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USD</td>\n",
       "      <td>19259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OIL</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XAU</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNY</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TWD</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDEX</td>\n",
       "      <td>10092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BTC</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NZD</td>\n",
       "      <td>2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JPY</td>\n",
       "      <td>6399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHF</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARS</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AUD</td>\n",
       "      <td>4946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EUR</td>\n",
       "      <td>12751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TRY</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MXN</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GBP</td>\n",
       "      <td>7172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAD</td>\n",
       "      <td>2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RUB</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  count\n",
       "0     USD  19259\n",
       "1     OIL   1988\n",
       "2     XAU   1446\n",
       "3     CNY   1522\n",
       "4     TWD     72\n",
       "5   INDEX  10092\n",
       "6     BTC   1096\n",
       "7     NZD   2953\n",
       "8     JPY   6399\n",
       "9     CHF   1600\n",
       "10    ARS     17\n",
       "11    AUD   4946\n",
       "12    EUR  12751\n",
       "13    TRY   1069\n",
       "14    MXN    582\n",
       "15    GBP   7172\n",
       "16    CAD   2620\n",
       "17    RUB    352"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'category')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.plot(x='cat', y='count', kind='bar', legend=False, grid=True, figsize=(8, 5))\n",
    "plt.title(\"Number of articles per category\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('category', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '# of categories')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "rowsums = df.iloc[:,2:].sum(axis=1)\n",
    "x=rowsums.value_counts()#plot\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x.index, x.values)\n",
    "plt.title(\"Multiple categories per comment\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of categories', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of comments that are not labelled:\n",
      "0.09466671442386905\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of comments that are not labelled:')\n",
    "print(len(df[(df['classes_target'].str.len()==0)]) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = df.body.dropna().map(lambda x: \" \".join(x)).str.len()\n",
    "lens.hist(bins = np.arange(0,5000,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression()):\n",
    "        self.base_classifier=base_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a Binary Relevance classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples, n_labels] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        \"\"\"\n",
    "\n",
    "        # list of individual classifiers\n",
    "        self.models = []\n",
    "       \n",
    "        # for every class label\n",
    "        for label in list(y.columns):\n",
    "            # Check that X and y have correct shape\n",
    "            x_checked, y_checked = check_X_y(X, y[label])\n",
    "            # every classifier is independent of the others\n",
    "            # hence we create a copy of the base classifier instance\n",
    "            base_model = clone(self.base_classifier)\n",
    "            # fit the base model - one model each for Y1, Y2....Y14\n",
    "            basel_model = base_model.fit(x_checked, y_checked)\n",
    "            # add the fitted model list of individual classifiers\n",
    "            self.models.append(base_model)\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i=0\n",
    "        # list of individual classifier predictions\n",
    "        preds = []\n",
    "        \n",
    "        # predict against each fitted model - one model per label\n",
    "        for model in self.models:\n",
    "            pred = model.predict(X)\n",
    "            # add the prediction to the dataframe\n",
    "            preds.append(pd.DataFrame({'Class'+ str(i+1): pred}))\n",
    "            i+=1\n",
    "        \n",
    "        # dataframe with predictions for all class labels\n",
    "        all_preds = pd.concat(preds, axis=1)\n",
    "        # standard sklearn classifiers return predictions as numpy arrays\n",
    "        # hence convert the dataframe to a numpy array\n",
    "        return all_preds.to_numpy()\n",
    "    \n",
    "\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i = 0\n",
    "        \n",
    "        for model in self.models:\n",
    "            # Call predict_proba of the each base model\n",
    "            pred = model.predict_proba(X)\n",
    "            # Add the probabilities of 1 to the dataframe\n",
    "            all_preds['Class'+str(i+1)] = [one_prob[1] for one_prob in pred]\n",
    "            i+=1\n",
    "        \n",
    "        #return probabilities\n",
    "        return all_preds.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_test, y_pred):\n",
    "    # y_pred is a numpy array, y_test is a dataframe\n",
    "    # to compare the two, convert to a single type\n",
    "    y_test = y_test.to_numpy()\n",
    "    \n",
    "    # shape of test and preds must be equal\n",
    "    assert y_test.shape == y_pred.shape\n",
    "    i=0\n",
    "    # list of scores for each training sample\n",
    "    scores = []\n",
    "    \n",
    "    # for each test sample\n",
    "    while i < len(y_test):\n",
    "        count=0\n",
    "        # count the number of matches in the sample\n",
    "        # y_test[i] -> row values in test set (true values)\n",
    "        # y_pred[i] -> row values in predictions set (predicted values)\n",
    "        for p, q in zip(y_test[i], y_pred[i]):\n",
    "            if p == q:\n",
    "                count += 1\n",
    "\n",
    "        # accuracy score for the sample = no. of correctly predicted labels/total no. of labels\n",
    "        scores.append(count / y_pred.shape[1])\n",
    "        i+=1 \n",
    "\n",
    "    # final accuracy = avg. accuracy over all test samples =\n",
    "    # sum of the accuracy of all training samples/no. of training samples\n",
    "    return round((sum(scores)/len(y_test)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifierUS(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression(max_iter=20000)):\n",
    "        self.base_classifier=base_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a Binary Relevance classifier with Under sampling from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        \"\"\"\n",
    "\n",
    "        # list of individual classifiers\n",
    "        self.models = []\n",
    "        \n",
    "        # for each class label\n",
    "        for label in list(y.columns):\n",
    "            \n",
    "            X_cp = X.copy()\n",
    "            # pick the column values for the label\n",
    "            y_cp = y[label]\n",
    "            \n",
    "            # sampling is done on both X and y, hence join the two dataframes\n",
    "            X_y_data = pd.concat([X_cp, y_cp], axis=1)\n",
    "            \n",
    "            # counters for 0 values and 1 values\n",
    "            n_val0, n_val1 = 0,0\n",
    "            \n",
    "            j=0\n",
    "            # for each sample\n",
    "            while j<len(X_y_data):\n",
    "                # if value for the label is 0\n",
    "                if(X_y_data.iloc[j][label] == 0):\n",
    "                    n_val0+=1\n",
    "                else:\n",
    "                    # value 1\n",
    "                    n_val1+=1\n",
    "                j+=1\n",
    "            \n",
    "            # under sample the majority class\n",
    "            # randomly pick samples from majority class equal to the number of samples in the minority class\n",
    "            # both the classes will have the same number of samples\n",
    "            if n_val0 > n_val1:\n",
    "                # majority 0 values\n",
    "                val1 = X_y_data[X_y_data[label]==1]\n",
    "                val0 = X_y_data[X_y_data[label]==0].sample(n_val1)\n",
    "                \n",
    "                X_y_data = pd.concat([val0, val1], axis=0)\n",
    "            \n",
    "            elif n_val1 > n_val0:\n",
    "                # majority 1 values\n",
    "                val1 = X_y_data[X_y_data[label]==1].sample(n_val0)\n",
    "                val0 = X_y_data[X_y_data[label]==0]\n",
    "                \n",
    "                X_y_data = pd.concat([val0, val1], axis=0)\n",
    "            \n",
    "            # split back into X and y\n",
    "            X_cp = X_y_data.iloc[:, :-1]\n",
    "            y_cp = X_y_data.iloc[:, -1]\n",
    "            \n",
    "            base_model = clone(self.base_classifier)\n",
    "            # fit the base model - one model each for Y1, Y2....Y14\n",
    "            a, b = check_X_y(X_cp, y_cp)\n",
    "            base_model.fit(a, b)\n",
    "            # list of individual classifiers classifiers\n",
    "            self.models.append(base_model)\n",
    "\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i=0\n",
    "        # list of individual classifier predictions\n",
    "        preds = []\n",
    "        \n",
    "        # for every fitted model\n",
    "        for model in self.models:\n",
    "            # predict for X\n",
    "            pred = model.predict(X)\n",
    "            # add to the list of predictions\n",
    "            preds.append(pd.DataFrame({'Class'+ str(i+1): pred}))\n",
    "            i+=1\n",
    "        \n",
    "        # store predictions for each label in a single dataframe\n",
    "        all_preds = pd.concat(preds, axis=1)\n",
    "        # standard sklearn classifiers return predictions as numpy arrays\n",
    "        # hence convert the dataframe to a numpy array\n",
    "        return all_preds.to_numpy()\n",
    "    \n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i = 0\n",
    "        \n",
    "        for model in self.models:\n",
    "            # Call predict_proba of the each base model\n",
    "            pred = model.predict_proba(X)\n",
    "            # Add the probabilities of 1 to the dataframe\n",
    "            all_preds['Class'+str(i+1)] = [one_prob[1] for one_prob in pred]\n",
    "            i+=1\n",
    "        \n",
    "        #return probabilities\n",
    "        return all_preds.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierChains(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression(max_iter=20000), order=None):\n",
    "        self.base_classifier=base_classifier\n",
    "        self.order = order\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a Classifier Chain from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples, n_labels] \n",
    "            The target values (class labels) as integers or strings.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # check the order parameter\n",
    "        if self.order is None:\n",
    "            # default value - natural order for number of labels\n",
    "            self.order = list(range(y.shape[1]))\n",
    "        elif self.order == 'random':\n",
    "            # random order\n",
    "            self.order = list(range(y.shape[1]))\n",
    "            random.shuffle(self.order)\n",
    "        else:\n",
    "            # order specified\n",
    "            if(len(self.order)==y.shape[1]):\n",
    "                # expect order from 1, hence reduce 1 to consider zero indexing\n",
    "                self.order = [o - 1 for o in self.order]\n",
    "    \n",
    "        \n",
    "        # list of base models for each class\n",
    "        self.models = [clone(self.base_classifier) for clf in range(y.shape[1])]\n",
    "\n",
    "        # create a copy of X\n",
    "        X_joined = X.copy()\n",
    "       # X_joined.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # create a new dataframe with X and y-in the order specified\n",
    "        # if order = [2,4,5,6...] -> X_joined= X, y2, y4, y5...\n",
    "        for val in self.order:\n",
    "            X_joined = pd.concat([X_joined, y['Class'+str(val+1)]], axis=1)\n",
    "\n",
    "        \n",
    "        # for each ith model, fit the model on X + y0 to yi-1 (in the order specified)\n",
    "        # if order = [2,4,6,....] fit 1st model on X for y2, fit second model on X+y2 for y4...\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            # select values of the class in order\n",
    "            y_vals = y.loc[:, 'Class'+str(self.order[chain_index]+1)]\n",
    "            # pick values for training - X+y upto the current label\n",
    "            t_X = X_joined.iloc[:, :(X.shape[1]+chain_index)]\n",
    "            check_X_y(t_X, y_vals)\n",
    "            # fit the model\n",
    "            model.fit(t_X, y_vals)\n",
    "\n",
    "\n",
    "            \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # dataframe to maintain previous predictions\n",
    "        pred_chain = pd.DataFrame(columns=['Class'+str(o+1) for o in self.order])\n",
    "        \n",
    "        X_copy = X.copy()\n",
    "        X_joined = X.copy()\n",
    "        \n",
    "        # use default indexing\n",
    "        X_joined.reset_index(drop=True, inplace=True)\n",
    "        X_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        i=0\n",
    "        \n",
    "        # for each ith model, predict based on X + predictions of all models upto i-1\n",
    "        # happens in the specified order since models are already fitted according to the order\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            # select previous predictions - all columns upto the current index\n",
    "            prev_preds = pred_chain.iloc[:, :chain_index]\n",
    "            # join the previous predictions with X\n",
    "            X_joined = pd.concat([X_copy, prev_preds], axis=1)\n",
    "            # predict on the base model\n",
    "            pred = model.predict(X_joined)\n",
    "            # add the new prediction to the pred chain\n",
    "            pred_chain['Class'+str(self.order[i]+1)] = pred\n",
    "            i+=1\n",
    "\n",
    "        # re-arrange the columns in natural order to return the predictions\n",
    "        pred_chain = pred_chain.loc[:, ['Class'+str(j+1) for j in range(0, len(self.order))]]\n",
    "        # all sklearn implementations return numpy array\n",
    "        # hence convert the dataframe to numpy array\n",
    "        return pred_chain.to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Function to predict probabilities of 1s\n",
    "    def predict_proba(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # dataframe to maintain previous predictions\n",
    "        pred_chain = pd.DataFrame(columns=['Class'+str(o+1) for o in self.order])\n",
    "        # dataframe to maintain probabilities of class labels\n",
    "        pred_probs = pd.DataFrame(columns=['Class'+str(o+1) for o in self.order])\n",
    "        X_copy = X.copy()\n",
    "        X_joined = X.copy()\n",
    "        \n",
    "        # use default indexing\n",
    "        X_joined.reset_index(drop=True, inplace=True)\n",
    "        X_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        i=0\n",
    "        \n",
    "        # for each ith model, predict based on X + predictions of all models upto i-1\n",
    "        # happens in the specified order since models are already fitted according to the order\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            \n",
    "            # select previous predictions - all columns upto the current index\n",
    "            prev_preds = pred_chain.iloc[:, :chain_index]\n",
    "            # join the previous predictions with X\n",
    "            X_joined = pd.concat([X_copy, prev_preds], axis=1)\n",
    "            # predict on the base model\n",
    "            pred = model.predict(X_joined)\n",
    "            # predict probabilities\n",
    "            pred_proba = model.predict_proba(X_joined)\n",
    "            # add the new prediction to the pred chain\n",
    "            pred_chain['Class'+str(self.order[i]+1)] = pred\n",
    "            # save the probabilities of 1 according to label order\n",
    "            pred_probs['Class'+str(self.order[i]+1)] = [one_prob[1] for one_prob in pred_proba]\n",
    "            i+=1\n",
    "\n",
    "        # re-arrange the columns in natural order to return the probabilities\n",
    "        pred_probs = pred_probs.loc[:, ['Class'+str(j+1) for j in range(0, len(self.order))]]\n",
    "        # all sklearn implementations return numpy array\n",
    "        # hence convert the dataframe to numpy array\n",
    "        return pred_probs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_remove = ['ARS','MXN','OIL','XAU','TRY','INDEX','BTC','TWD','RUB','CHF']\n",
    "df = df.drop(labels=to_remove,axis=1)\n",
    "classes = [cls for cls in classes if cls not in to_remove]\n",
    "df['text_clean'] = df.body.map(lambda x: \" \".join(list(x)) if type(x) is list else \"\" ).map(lambda com : clean_text(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[classes].sum(axis=1)\n",
    "df = df.sample(n=3000)\n",
    "train, test = train_test_split(df[(df[classes].sum(axis=1)>0)], random_state=42, test_size=0.50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB_pipeline = Pipeline([\n",
    "#                 ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "#                 ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "#                     fit_prior=True, class_prior=None))),\n",
    "#             ])\n",
    "# for category in categories:\n",
    "#     print('... Processing {}'.format(category))\n",
    "#     # train the model using X_dtm & y\n",
    "#     NB_pipeline.fit(X_train, train[category])\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = NB_pipeline.predict(X_test)\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "#     print('Balanced Test accuracy is {}'.format(balanced_accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogReg_pipeline = Pipeline([\n",
    "#                 ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "#                 ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "#             ])\n",
    "# for category in categories:\n",
    "#     print('... Processing {}'.format(category))\n",
    "#     # train the model using X_dtm & y\n",
    "#     LogReg_pipeline.fit(X_train, train[category])\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = LogReg_pipeline.predict(X_test)\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC_pipeline = Pipeline([\n",
    "#                 ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "#                 ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "#             ])\n",
    "# for category in categories:\n",
    "#     print('... Processing {}'.format(category))\n",
    "#     # train the model using X_dtm & y\n",
    "#     SVC_pipeline.fit(X_train, train[category])\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = SVC_pipeline.predict(X_test)\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "vectorizer.fit(train.text_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using classifier chains\n",
    "# from skmultilearn.problem_transform import ClassifierChain\n",
    "# from sklearn.linear_model import LogisticRegression# initialize classifier chains multi-label classifier\n",
    "# classifier = ClassifierChain(LogisticRegression())# Training logistic regression model on train data\n",
    "# classifier.fit(x, y)# predict\n",
    "# predictions = classifier.predict(vectorizer.transform(X_test))# accuracy\n",
    "# print(\"Accuracy = \",accuracy_score(test.drop(labels=['_id','summary','body','text_clean','classes_target','classes_body','classes_summary','classes_title','title'],axis=1),predictions))\n",
    "# print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n =400\n",
    "# listdf = [train[i:i+n] for i in range(0,train.shape[0],n)]\n",
    "\n",
    "# from skmultilearn.problem_transform import BinaryRelevance\n",
    "# from sklearn.naive_bayes import GaussianNB# initialize binary relevance multi-label classifier\n",
    "# # with a gaussian naive bayes base classifier\n",
    "# classifier = BinaryRelevance(GaussianNB())# train\n",
    "# # classifier.fit(x_train, y_train)# predict\n",
    "# # predictions = classifier.predict(x_test)# accuracy\n",
    "# # print(\"Accuracy = \",accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in listdf:\n",
    "#     X_train = vectorizer.transform(x.text_clean)\n",
    "#     y_train = x.drop(labels=['_id','summary','body','text_clean','classes_target','classes_body','classes_summary','classes_title','title'],axis=1)\n",
    "#     classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listdf = [test[i:i+n] for i in range(0,test.shape[0],n)]\n",
    "# predictions = []\n",
    "# for x in listdf:\n",
    "#     predictions.append(classifier.predict(vectorizer.transform(x.text_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee = [item[0].toarray()[0] for sub_list in predictions for item in sub_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "br_clf = BinaryRelevanceClassifier(LogisticRegression())\n",
    "# fit\n",
    "br_clf.fit(vectorizer.transform(train.text_clean).toarray(), train[classes])\n",
    "# predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = br_clf.predict(vectorizer.transform(test.text_clean).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape: (1189, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_pred.shape: \" + str(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Binary Relevance Classifier: 0.86638\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Binary Relevance Classifier: \" + str(accuracy_score(test[classes], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train.text_clean).toarray()\n",
    "y_train = train[classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=   7.8s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=   9.0s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=   9.2s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=   8.4s\n",
      "[CV] base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2) \n",
      "[CV]  base_classifier=DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2), total=   7.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  23.4s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  18.9s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  19.5s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  21.8s\n",
      "[CV] base_classifier=RandomForestClassifier(criterion='entropy') .....\n",
      "[CV]  base_classifier=RandomForestClassifier(criterion='entropy'), total=  18.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   5.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   4.9s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   4.4s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   5.0s\n",
      "[CV] base_classifier=LogisticRegression(max_iter=20000) ..............\n",
      "[CV]  base_classifier=LogisticRegression(max_iter=20000), total=   4.7s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   2.3s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   2.5s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   2.7s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   2.4s\n",
      "[CV] base_classifier=GaussianNB() ....................................\n",
      "[CV] ..................... base_classifier=GaussianNB(), total=   2.3s\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total=  55.2s\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total=  55.1s\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total=  54.1s\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total=  55.3s\n",
      "[CV] base_classifier=KNeighborsClassifier() ..........................\n",
      "[CV] ........... base_classifier=KNeighborsClassifier(), total=  54.0s\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.5min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.5min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.5min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.5min\n",
      "[CV] base_classifier=SVC() ...........................................\n",
      "[CV] ............................ base_classifier=SVC(), total= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 20.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_classifier': DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9756939999999998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_folds=5\n",
    "\n",
    "# Set up the parameter grid to search\n",
    "param_grid ={'base_classifier': [DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2),\n",
    "                                 RandomForestClassifier(criterion='entropy'),\n",
    "                                 LogisticRegression(max_iter=20000), GaussianNB(), KNeighborsClassifier(), SVC()] }\n",
    "\n",
    "# Perform the search\n",
    "# Using the custom accuracy function defined earlier\n",
    "tuned_model = GridSearchCV(BinaryRelevanceClassifier(), \\\n",
    "                            param_grid, scoring=make_scorer(accuracy_score), verbose = 2, cv=cv_folds)\n",
    "tuned_model.fit(X_train, y_train)\n",
    "\n",
    "# Print details of the best model\n",
    "print(\"Best Parameters Found: \")\n",
    "display(tuned_model.best_params_)\n",
    "display(tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifierUS(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression(max_iter=20000)):\n",
    "        self.base_classifier=base_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a Binary Relevance classifier with Under sampling from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        \"\"\"\n",
    "\n",
    "        # list of individual classifiers\n",
    "        self.models = []\n",
    "        \n",
    "        # for each class label\n",
    "        for label in list(y.columns):\n",
    "            \n",
    "            X_cp = X.copy()\n",
    "            # pick the column values for the label\n",
    "            y_cp = y[label]\n",
    "            \n",
    "            # sampling is done on both X and y, hence join the two dataframes\n",
    "            X_y_data = pd.concat([X_cp, y_cp], axis=1)\n",
    "            \n",
    "            # counters for 0 values and 1 values\n",
    "            n_val0, n_val1 = 0,0\n",
    "            \n",
    "            j=0\n",
    "            # for each sample\n",
    "            while j<len(X_y_data):\n",
    "                # if value for the label is 0\n",
    "                if(X_y_data.iloc[j][label] == 0):\n",
    "                    n_val0+=1\n",
    "                else:\n",
    "                    # value 1\n",
    "                    n_val1+=1\n",
    "                j+=1\n",
    "            \n",
    "            # under sample the majority class\n",
    "            # randomly pick samples from majority class equal to the number of samples in the minority class\n",
    "            # both the classes will have the same number of samples\n",
    "            if n_val0 > n_val1:\n",
    "                # majority 0 values\n",
    "                val1 = X_y_data[X_y_data[label]==1]\n",
    "                val0 = X_y_data[X_y_data[label]==0].sample(n_val1).reset_index(drop=True)\n",
    "                \n",
    "                X_y_data = pd.concat([val0, val1], axis=0)\n",
    "            \n",
    "            elif n_val1 > n_val0:\n",
    "                # majority 1 values\n",
    "                val1 = X_y_data[X_y_data[label]==1].sample(n_val0).reset_index(drop=True)\n",
    "                val0 = X_y_data[X_y_data[label]==0]\n",
    "                \n",
    "                X_y_data = pd.concat([val0, val1], axis=0)\n",
    "            \n",
    "            # split back into X and y\n",
    "            X_cp = X_y_data.iloc[:, :-1]\n",
    "            y_cp = X_y_data.iloc[:, -1]\n",
    "            \n",
    "            base_model = clone(self.base_classifier)\n",
    "            # fit the base model - one model each for Y1, Y2....Y14\n",
    "            a, b = check_X_y(X_cp, y_cp)\n",
    "            base_model.fit(a, b)\n",
    "            # list of individual classifiers classifiers\n",
    "            self.models.append(base_model)\n",
    "\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i=0\n",
    "        # list of individual classifier predictions\n",
    "        preds = []\n",
    "        \n",
    "        # for every fitted model\n",
    "        for model in self.models:\n",
    "            # predict for X\n",
    "            pred = model.predict(X)\n",
    "            # add to the list of predictions\n",
    "            preds.append(pd.DataFrame({'Class'+ str(i+1): pred}))\n",
    "            i+=1\n",
    "        \n",
    "        # store predictions for each label in a single dataframe\n",
    "        all_preds = pd.concat(preds, axis=1)\n",
    "        # standard sklearn classifiers return predictions as numpy arrays\n",
    "        # hence convert the dataframe to a numpy array\n",
    "        return all_preds.to_numpy()\n",
    "    \n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i = 0\n",
    "        \n",
    "        for model in self.models:\n",
    "            # Call predict_proba of the each base model\n",
    "            pred = model.predict_proba(X)\n",
    "            # Add the probabilities of 1 to the dataframe\n",
    "            all_preds['Class'+str(i+1)] = [one_prob[1] for one_prob in pred]\n",
    "            i+=1\n",
    "        \n",
    "        #return probabilities\n",
    "        return all_preds.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape=(1189, 8)\n"
     ]
    }
   ],
   "source": [
    "brus_clf = BinaryRelevanceClassifierUS()\n",
    "train = train.reset_index()\n",
    "# .\n",
    "brus_clf.fit(pd.DataFrame(vectorizer.transform(train.text_clean).toarray()), train[classes])\n",
    "\n",
    "# predict br_clf.fit(vectorizer.transform(train.text_clean).toarray(), train[classes])\n",
    "y_pred = brus_clf.predict(vectorizer.transform(test.text_clean).toarray())\n",
    "print(\"y_pred.shape=\" + str(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Binary Relevance Classifier with Under-sampling: 0.87048\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Binary Relevance Classifier with Under-sampling: \" + str(accuracy_score(test[classes], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "toarray() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10977/1306403589.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m tuned_model = GridSearchCV(BinaryRelevanceClassifierUS(), \\\n\u001b[1;32m     11\u001b[0m                             param_grid, scoring=make_scorer(accuracy_score), verbose = 2, cv=cv_folds)\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtuned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Print details of the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: toarray() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "cv_folds=5\n",
    "\n",
    "# Set up the parameter grid to search\n",
    "param_grid ={'base_classifier': [DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=2),\n",
    "                                 RandomForestClassifier(criterion='entropy'),\n",
    "                                 LogisticRegression(max_iter=20000), GaussianNB(), KNeighborsClassifier(), SVC()] }\n",
    "\n",
    "# Perform the search\n",
    "# Using the custom accuracy function defined earlier\n",
    "tuned_model = GridSearchCV(BinaryRelevanceClassifierUS(), \\\n",
    "                            param_grid, scoring=make_scorer(accuracy_score), verbose = 2, cv=cv_folds)\n",
    "tuned_model.fit(pd.DataFrame(vectorizer.transform(train.text_clean).toarray()), train[classes])\n",
    "\n",
    "# Print details of the best model\n",
    "print(\"Best Parameters Found: \")\n",
    "display(tuned_model.best_params_)\n",
    "display(tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
